{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a8a646c",
   "metadata": {},
   "source": [
    "# Code for labeling (not training) all data given model weights\n",
    "\n",
    "### Note\n",
    "There is an error where the prediction function will be incorrect if there is a single item in the final batch. We have been fixing this manually because of the few times we had to run the notebook, so keep this error in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463fb946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key savefig.frameon in file C:\\Users\\theth\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 421 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file C:\\Users\\theth\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 472 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file C:\\Users\\theth\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 473 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.1/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In C:\\Users\\theth\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\theth\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\theth\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\theth\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\theth\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\theth\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\theth\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\theth\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import regex as re\n",
    "\n",
    "\n",
    "import os\n",
    "import random as rand\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from clean_text import stopwords_make, punctstr_make, unicode_make, apache_tokenize, clean_sentence_apache \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import sys, argparse\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "from transformers import LongformerModel, LongformerTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e5c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = 'model_orgs.bin'\n",
    "test_files = 'filtered_preprocessed_texts_65365_110521.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13798c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_test_data(path):\n",
    "    return open(path, 'rb')\n",
    "with open_test_data(test_files) as f:\n",
    "    cult = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b473c1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/vol_b/data/jstor_data/ocr/journal-article-10....</td>\n",
       "      <td>[[Research, Note, Church, Membership, in, The,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/vol_b/data/jstor_data/ocr/journal-article-10....</td>\n",
       "      <td>[[polish, (io),oo, sociological, review, ISSN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/vol_b/data/jstor_data/ocr/journal-article-10....</td>\n",
       "      <td>[[Article, ■jjDlBSj, grapliy, Compassionate, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/vol_b/data/jstor_data/ocr/journal-article-10....</td>\n",
       "      <td>[[REPLY, TO, ALLISON:, MORE, ON, COMPARING, RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/vol_b/data/jstor_data/ocr/journal-article-10....</td>\n",
       "      <td>[[Determinants, of, Spousal, Interaction:, Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65360</th>\n",
       "      <td>/vol_b/data/jstor_data/ocr/journal-article-10....</td>\n",
       "      <td>[[JOURNAL, OF, MANAGERIAL, ISSUES, Vol., XXIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65361</th>\n",
       "      <td>/vol_b/data/jstor_data/ocr/journal-article-10....</td>\n",
       "      <td>[[Social, Psychology, Quarterly, Vol., No., Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65362</th>\n",
       "      <td>/vol_b/data/jstor_data/ocr/journal-article-10....</td>\n",
       "      <td>[[COMPULSORY, CLOSETS, AND, THE, SOCIAL, CONTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65363</th>\n",
       "      <td>/vol_b/data/jstor_data/ocr/journal-article-10....</td>\n",
       "      <td>[[mir, vol., mir, IfflullQQOITIOiii, Internoti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65364</th>\n",
       "      <td>/vol_b/data/jstor_data/ocr/journal-article-10....</td>\n",
       "      <td>[[Stranger, Intervention, into, Child, Punishm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65365 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               file_name  \\\n",
       "0      /vol_b/data/jstor_data/ocr/journal-article-10....   \n",
       "1      /vol_b/data/jstor_data/ocr/journal-article-10....   \n",
       "2      /vol_b/data/jstor_data/ocr/journal-article-10....   \n",
       "3      /vol_b/data/jstor_data/ocr/journal-article-10....   \n",
       "4      /vol_b/data/jstor_data/ocr/journal-article-10....   \n",
       "...                                                  ...   \n",
       "65360  /vol_b/data/jstor_data/ocr/journal-article-10....   \n",
       "65361  /vol_b/data/jstor_data/ocr/journal-article-10....   \n",
       "65362  /vol_b/data/jstor_data/ocr/journal-article-10....   \n",
       "65363  /vol_b/data/jstor_data/ocr/journal-article-10....   \n",
       "65364  /vol_b/data/jstor_data/ocr/journal-article-10....   \n",
       "\n",
       "                                                    text  \n",
       "0      [[Research, Note, Church, Membership, in, The,...  \n",
       "1      [[polish, (io),oo, sociological, review, ISSN,...  \n",
       "2      [[Article, ■jjDlBSj, grapliy, Compassionate, a...  \n",
       "3      [[REPLY, TO, ALLISON:, MORE, ON, COMPARING, RE...  \n",
       "4      [[Determinants, of, Spousal, Interaction:, Mar...  \n",
       "...                                                  ...  \n",
       "65360  [[JOURNAL, OF, MANAGERIAL, ISSUES, Vol., XXIII...  \n",
       "65361  [[Social, Psychology, Quarterly, Vol., No., Tr...  \n",
       "65362  [[COMPULSORY, CLOSETS, AND, THE, SOCIAL, CONTE...  \n",
       "65363  [[mir, vol., mir, IfflullQQOITIOiii, Internoti...  \n",
       "65364  [[Stranger, Intervention, into, Child, Punishm...  \n",
       "\n",
       "[65365 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee8d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "full_text = []\n",
    "\n",
    "for i in cult['text']:\n",
    "    joined = list(itertools.chain(*i))\n",
    "    full_text.append(\" \".join(joined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9eb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "cult['full_text'] = full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dad37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(article):\n",
    "    article = re.sub('<plain_text> <page sequence=\"1\">', '', article)\n",
    "    article = re.sub(r'</page>(\\<.*?\\>)', ' \\n ', article)\n",
    "    # xml tags\n",
    "    article = re.sub(r'<.*?>', '', article)\n",
    "    article = re.sub(r'<body.*\\n\\s*.*\\s*.*>', '', article)\n",
    "    return article\n",
    "\n",
    "tags_removed = [remove_tags(art) for art in cult['full_text']]\n",
    "cult['text_no_tags'] = tags_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4a71632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1070 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15ba859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "\n",
    "        \n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            self.dropout = nn.Dropout(p=params['dropout'])\n",
    "        else:\n",
    "            self.dropout = None\n",
    "            \n",
    "#         self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=False, do_basic_tokenize=False)\n",
    "#         self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "        self.max_length = params['max_length'] if 'max_length' in params else 768\n",
    "        \n",
    "        self.tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "        self.bert = LongformerModel.from_pretrained(\"allenai/longformer-base-4096\", gradient_checkpointing=True)\n",
    "\n",
    "        self.num_labels = params[\"label_length\"]\n",
    "\n",
    "        self.fc = nn.Linear(768, self.num_labels)\n",
    "\n",
    "    def get_batches(self, all_x, all_y, batch_size=10):\n",
    "\n",
    "        \"\"\" Get batches for input x, y data, with data tokenized according to the BERT tokenizer \n",
    "        (and limited to a maximum number of WordPiece tokens \"\"\"\n",
    "\n",
    "        batches_x=[]\n",
    "        batches_y=[]\n",
    "\n",
    "        for i in range(0, len(all_x), batch_size):\n",
    "\n",
    "            current_batch=[]\n",
    "\n",
    "            x=all_x[i:i+batch_size]\n",
    "\n",
    "            batch_x = self.tokenizer(x, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "            batch_y=all_y[i:i+batch_size]\n",
    "\n",
    "            batches_x.append(batch_x.to(device))\n",
    "            batches_y.append(torch.LongTensor(batch_y).to(device))\n",
    "\n",
    "        return batches_x, batches_y\n",
    "\n",
    "\n",
    "    def forward(self, batch_x): \n",
    "\n",
    "        bert_output = self.bert(input_ids=batch_x[\"input_ids\"],\n",
    "                         attention_mask=batch_x[\"attention_mask\"],\n",
    "#                          token_type_ids=batch_x[\"token_type_ids\"],\n",
    "                         output_hidden_states=True)\n",
    "\n",
    "        # We're going to represent an entire document just by its [CLS] embedding (at position 0)\n",
    "        # And use the *last* layer output (layer -1)\n",
    "        # as a result of this choice, this embedding will be optimized for this purpose during the training process.\n",
    "\n",
    "        bert_hidden_states = bert_output['hidden_states']\n",
    "\n",
    "        out = bert_hidden_states[-1][:,0,:]\n",
    "        \n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out.squeeze()\n",
    "\n",
    "    def evaluate(self, batch_x, batch_y):\n",
    "\n",
    "        self.eval()\n",
    "        corr = 0.\n",
    "        total = 0.\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in zip(batch_x, batch_y):\n",
    "                y_preds = self.forward(x)\n",
    "                for idx, y_pred in enumerate(y_preds):\n",
    "                    prediction=torch.argmax(y_pred)\n",
    "                    if prediction == y[idx]:\n",
    "                        corr += 1.\n",
    "                    total+=1                          \n",
    "        return corr/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "589046d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, batch_x, batch_y):\n",
    "    \"\"\"\n",
    "    given a certain model, outputs predictions for the batch_x\n",
    "    Note that batch_y contains dummy labels to take advantage of pre-existing batching code\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(zip(batch_x, batch_y)):\n",
    "            y_preds = model.forward(x)\n",
    "            for idx, y_pred in enumerate(y_preds):\n",
    "                predictions.append(torch.argmax(y_pred).item())\n",
    "                sm = F.softmax(y_pred, dim=0)\n",
    "                try:\n",
    "                    scores.append(sm[1].item())\n",
    "                except:\n",
    "                    \n",
    "                    print(len(scores))\n",
    "                    print(sm.shape, sm)\n",
    "    return predictions, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59c09a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BERTClassifier({'label_length': 2})\n",
    "if torch.cuda.is_available():    \n",
    "    \n",
    "    model.load_state_dict(torch.load(model_location))\n",
    "    model = model.to(device)\n",
    "# If not...\n",
    "else:\n",
    "    model.load_state_dict(torch.load(model_location, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f2b1c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train1 = cult['text_no_tags']\n",
    "y_train1 = np.zeros(len(X_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0b4b600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_x, batch_y = model.get_batches(list(X_train1), list(y_train1), batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27b91572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32683it [5:51:45,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65364\n",
      "torch.Size([]) tensor(1., device='cuda:0')\n",
      "65364\n",
      "torch.Size([]) tensor(1., device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds, scores = get_preds(model, batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6acdc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'{model_location}_pred.pkl', 'wb') as f:\n",
    "#     pickle.dump(preds, f)\n",
    "\n",
    "# with open(f'{model_location}_score.pkl', 'wb') as f:\n",
    "#     pickle.dump(scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5fb9cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'{model_location}_pred.pkl', 'rb') as f:\n",
    "#     preds = pickle.load(f)\n",
    "\n",
    "# with open(f'{model_location}_score.pkl', 'rb') as f:\n",
    "#     scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6bfdce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0.1411495953798294, 0.5261998772621155, 0.0008700518519617617, 0.0008788488921709359, 0.030665069818496704, 0.016456294804811478, 0.012148287147283554, 0.00021816176013089716, 0.08609135448932648, 0.9997815489768982]\n"
     ]
    }
   ],
   "source": [
    "print(preds[:10])\n",
    "print(scores[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be2470f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred, score in zip(preds, scores):\n",
    "    if pred == 1:\n",
    "        assert score >= 0.5\n",
    "    else:\n",
    "        assert score <= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39ed743e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65366"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1af54588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.5446, -1.8247], device='cuda:0', grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.forward(batch_x[-1])\n",
    "F.softmax(out, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6f0a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[65364] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d96f6525",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[65364] = 0.0125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6c6ea93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010806157253682613,\n",
       " 0.0004782340838573873,\n",
       " 0.7749702334403992,\n",
       " 0.00039812311297282577,\n",
       " 0.9839450716972351,\n",
       " 0.000224292729399167,\n",
       " 0.011638615280389786,\n",
       " 0.11250873655080795,\n",
       " 0.013985664583742619,\n",
       " 0.99974]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f'{model_location}_pred.pkl', 'wb') as f:\n",
    "    pickle.dump(preds, f)\n",
    "\n",
    "with open(f'{model_location}_score.pkl', 'wb') as f:\n",
    "    pickle.dump(scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143d0eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
