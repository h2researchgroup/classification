{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare classification methods for identifying org. science perspectives in JSTOR articles\n",
    "## Using grid search and balanced samples from hand-labeled set of articles\n",
    "\n",
    "@author: Thomas Lu, Jaren Haber PhD<br>\n",
    "@coauthors: Prof. Heather Haveman, UC Berkeley; Yoon Sung Hong, Wayfair<br>\n",
    "@contact: Jaren.Haber@georgetown.edu<br>\n",
    "@project: Computational Literature Review of Organizational Scholarship<br>\n",
    "@date: September 2021\n",
    "\n",
    "'''\n",
    "Trains classifiers to predict whether an article is about a given perspective in org. science. To train the classifiers, uses preliminary labeled articles, broken down as follows: \n",
    "Cultural: 105 yes, 209 no\n",
    "Relational: 92 yes, 230 no\n",
    "Demographic: 77 yes, 249 no\n",
    "Compares f1_weighted scores of four model structures using 10-Fold Cross Validation: Logistic regression, SVM, Naive Bayes, and Decision Tree. Oversamples training data to .7 (7:10 minority:majority class).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Import libraries\n",
    "######################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import csv\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, PassiveAggressiveClassifier, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, KFold\n",
    "# from sklearn.experimental import enable_hist_gradient_boosting\n",
    "\n",
    "# !pip install imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "\n",
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "import sys; sys.path.insert(0, \"../preprocess/\") # For loading functions from files in other directory\n",
    "from quickpickle import quickpickle_dump, quickpickle_load # custom scripts for quick saving & loading to pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Define filepaths\n",
    "######################################################\n",
    "\n",
    "data_folder = 'classification'\n",
    "folder = 'tlu_test'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "root = str.replace(cwd, f'{folder}/modeling', '')\n",
    "\n",
    "thisday = date.today().strftime(\"%m%d%y\")\n",
    "\n",
    "# Directory for prepared data and trained models: save files here\n",
    "data_fp = root + f'{data_folder}/data/'\n",
    "model_fp = root + f'{folder}/models/'\n",
    "logs = root + f'{folder}/modeling/logs/'\n",
    "\n",
    "w2v_fp = root + 'models_storage/word_embeddings_data/word2vec_phrased_filtered_300d_2020_sept5.bin'\n",
    "\n",
    "# Current article lists\n",
    "article_list_fp = data_fp + 'filtered_length_index.csv' # Filtered index of research articles\n",
    "article_paths_fp = data_fp + 'filtered_length_article_paths.csv' # List of article file paths\n",
    "\n",
    "# Preprocessed training data\n",
    "cult_labeled_fp = data_fp + 'training_cultural_preprocessed_022621.pkl'\n",
    "relt_labeled_fp = data_fp + 'training_relational_preprocessed_022621.pkl'\n",
    "demog_labeled_fp = data_fp + 'training_demographic_preprocessed_022621.pkl'\n",
    "orgs_labeled_fp = data_fp + 'training_orgs_preprocessed_022621.pkl'\n",
    "\n",
    "# Model filepaths\n",
    "cult_model_fp = model_fp + f'classifier_cult_MLP_{str(thisday)}.joblib'\n",
    "relt_model_fp = model_fp + f'classifier_relt_MLP_{str(thisday)}.joblib'\n",
    "demog_model_fp = model_fp + f'classifier_demog_MLP_{str(thisday)}.joblib'\n",
    "orgs_model_fp = model_fp + f'classifier_orgs_MLP_{str(thisday)}.joblib'\n",
    "\n",
    "# # Vectorizers trained on hand-coded data (use to limit vocab of input texts)\n",
    "# cult_vec_fp = model_fp + 'vectorizer_cult_022621.joblib'\n",
    "# relt_vec_fp = model_fp + 'vectorizer_relt_022621.joblib'\n",
    "# demog_vec_fp = model_fp + 'vectorizer_demog_022621.joblib'\n",
    "# orgs_vec_fp = model_fp + 'vectorizer_orgs_022621.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the word2vec model\n",
    "\n",
    "w2v_model = KeyedVectors.load(w2v_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cultural_score</th>\n",
       "      <th>primary_subject</th>\n",
       "      <th>edited_filename</th>\n",
       "      <th>article_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[research, note, church_membership, netherlan...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sociology</td>\n",
       "      <td>10.1086_210179</td>\n",
       "      <td>Where Do Interorganizational Networks Come From?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[polish, io_oo, sociological_review, issn, co...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sociology</td>\n",
       "      <td>10.1086_210317</td>\n",
       "      <td>Civil Rights Law at Work: Sex Discrimination a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[article, jjdlbsj, grapliy, compassionate, eg...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sociology</td>\n",
       "      <td>10.1086_231084</td>\n",
       "      <td>Between Markets and Politics: Organizational R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[reply, allison, more, comparing, regression_...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sociology</td>\n",
       "      <td>10.1086_231174</td>\n",
       "      <td>World Society and the Nation‐State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[determinants, spousal, interaction, marital,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sociology</td>\n",
       "      <td>10.1086_382347</td>\n",
       "      <td>Kinship Networks and Entrepreneurs in China’s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[wsê, ih, ompany, profile, john, porter, musé...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sociology</td>\n",
       "      <td>10.1086_517899</td>\n",
       "      <td>What Is Organizational Imprinting? Cultural En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[andrew_christensen, university_california, l...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sociology</td>\n",
       "      <td>10.1086_588742</td>\n",
       "      <td>Homeward Bound? Interest, Identity, and Invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[lawyers, consumer_protection, laws, stewart_...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sociology</td>\n",
       "      <td>10.1086_657524</td>\n",
       "      <td>Corporate Unity in American Trade Policy: A Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[establishing, sense, personal, control, tran...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sociology</td>\n",
       "      <td>10.1086_659639</td>\n",
       "      <td>The Credit Crisis as a Problem in the Sociolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[guess, who, coming, town, white_supremacy, e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sociology</td>\n",
       "      <td>10.1525_irqr.2011.4.3.199</td>\n",
       "      <td>Science, Health, and Nationhood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cultural_score  \\\n",
       "0  [[research, note, church_membership, netherlan...             0.0   \n",
       "1  [[polish, io_oo, sociological_review, issn, co...             1.0   \n",
       "2  [[article, jjdlbsj, grapliy, compassionate, eg...             0.0   \n",
       "3  [[reply, allison, more, comparing, regression_...             1.0   \n",
       "4  [[determinants, spousal, interaction, marital,...             1.0   \n",
       "5  [[wsê, ih, ompany, profile, john, porter, musé...             1.0   \n",
       "6  [[andrew_christensen, university_california, l...             1.0   \n",
       "7  [[lawyers, consumer_protection, laws, stewart_...             0.0   \n",
       "8  [[establishing, sense, personal, control, tran...             1.0   \n",
       "9  [[guess, who, coming, town, white_supremacy, e...             0.0   \n",
       "\n",
       "  primary_subject            edited_filename  \\\n",
       "0       Sociology             10.1086_210179   \n",
       "1       Sociology             10.1086_210317   \n",
       "2       Sociology             10.1086_231084   \n",
       "3       Sociology             10.1086_231174   \n",
       "4       Sociology             10.1086_382347   \n",
       "5       Sociology             10.1086_517899   \n",
       "6       Sociology             10.1086_588742   \n",
       "7       Sociology             10.1086_657524   \n",
       "8       Sociology             10.1086_659639   \n",
       "9       Sociology  10.1525_irqr.2011.4.3.199   \n",
       "\n",
       "                                        article_name  \n",
       "0   Where Do Interorganizational Networks Come From?  \n",
       "1  Civil Rights Law at Work: Sex Discrimination a...  \n",
       "2  Between Markets and Politics: Organizational R...  \n",
       "3                 World Society and the Nation‐State  \n",
       "4  Kinship Networks and Entrepreneurs in China’s ...  \n",
       "5  What Is Organizational Imprinting? Cultural En...  \n",
       "6  Homeward Bound? Interest, Identity, and Invest...  \n",
       "7  Corporate Unity in American Trade Policy: A Ne...  \n",
       "8  The Credit Crisis as a Problem in the Sociolog...  \n",
       "9                    Science, Health, and Nationhood  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cult_df = quickpickle_load(cult_labeled_fp)\n",
    "relt_df = quickpickle_load(relt_labeled_fp)\n",
    "demog_df = quickpickle_load(demog_labeled_fp)\n",
    "orgs_df = quickpickle_load(orgs_labeled_fp)\n",
    "\n",
    "cult_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cultural_score\n",
      "0.0    475\n",
      "0.5     24\n",
      "1.0    234\n",
      "dtype: int64\n",
      "\n",
      "relational_score\n",
      "0.0    420\n",
      "0.5     29\n",
      "1.0    287\n",
      "dtype: int64\n",
      "\n",
      "demographic_score\n",
      "0.0    477\n",
      "0.5      7\n",
      "1.0    256\n",
      "dtype: int64\n",
      "\n",
      "orgs_score\n",
      "0.0    303\n",
      "0.5     10\n",
      "1.0    511\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check score distribution across classes\n",
    "print(cult_df.groupby('cultural_score').size())\n",
    "print()\n",
    "print(relt_df.groupby('relational_score').size())\n",
    "print()\n",
    "print(demog_df.groupby('demographic_score').size())\n",
    "print()\n",
    "print(orgs_df.groupby('orgs_score').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unsure cases: where X_score = 0.5\n",
    "drop_unsure = True\n",
    "\n",
    "if drop_unsure:\n",
    "    cult_df_yes = cult_df[cult_df['cultural_score'] == 1.0]\n",
    "    cult_df_no = cult_df[cult_df['cultural_score'] == 0.0]\n",
    "    cult_df = pd.concat([cult_df_yes, cult_df_no])\n",
    "    \n",
    "    relt_df_yes = relt_df[relt_df['relational_score'] == 1.0]\n",
    "    relt_df_no = relt_df[relt_df['relational_score'] == 0.0]\n",
    "    relt_df = pd.concat([relt_df_yes, relt_df_no])\n",
    "    \n",
    "    demog_df_yes = demog_df[demog_df['demographic_score'] == 1.0]\n",
    "    demog_df_no = demog_df[demog_df['demographic_score'] == 0.0]\n",
    "    demog_df = pd.concat([demog_df_yes, demog_df_no])\n",
    "    \n",
    "    orgs_df_yes = orgs_df[orgs_df['orgs_score'] == 1.0]\n",
    "    orgs_df_no = orgs_df[orgs_df['orgs_score'] == 0.0]\n",
    "    orgs_df = pd.concat([orgs_df_yes, orgs_df_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Baseline: Create a paragraph embedding by averaging word embeddings\n",
    "######################################################\n",
    "\n",
    "def obtain_mean_vector(list_of_sentences, dim=300):\n",
    "    \"\"\"\n",
    "    Obtains the preprocessed article and returns the mean of all existing word embeddings\n",
    "    \n",
    "    Args:\n",
    "        list_of_sentences: a list of the tokenized sentences of words or phrases which constitute the article\n",
    "        dim: the dimensions of the word vectors (default is 300)\n",
    "        \n",
    "    Returns:\n",
    "        A vector of shape (300, ) characterizing the input sentences\n",
    "    \n",
    "    \n",
    "    Stopwords and infrequent words don't need to be filtered \n",
    "    because they are not in the word2vec instance\n",
    "    \"\"\"\n",
    "    \n",
    "    i = 0\n",
    "    sum_vec = np.zeros(shape=(dim,))\n",
    "    for sent in list_of_sentences:\n",
    "        for word in sent:\n",
    "            if word in w2v_model.wv:\n",
    "                sum_vec += w2v_model.wv[word]\n",
    "                i += 1\n",
    "    return sum_vec / i\n",
    "\n",
    "\n",
    "def transform_dataframe(df):\n",
    "    return np.stack(df.text.apply(obtain_mean_vector))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(814, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the data\n",
    "\n",
    "X_orgs = transform_dataframe(orgs_df)\n",
    "\n",
    "X_cult = transform_dataframe(cult_df)\n",
    "\n",
    "X_relt = transform_dataframe(relt_df)\n",
    "\n",
    "X_demog = transform_dataframe(demog_df)\n",
    "\n",
    "X_orgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Generates Balanced Pipelines\n",
    "######################################################\n",
    "\n",
    "def make_model_pipeline(model, undersample=False, sampling_ratio = 1.0, use_SMOTE=False, random_state=None):\n",
    "    \"\"\"\n",
    "    Creates an sklearn pipeline object to handle over/under sampling or SMOTE sampling\n",
    "    This is to avoid data leakage from oversampling before partitioning for cross-validation\n",
    "    Apparently, this will not effect the test data when running grid search, which is desired\n",
    "    \n",
    "    Args:\n",
    "        model: An sklearn classifier model to be packaged with an over/under sampling model\n",
    "        undersample: boolean for over or undersampling\n",
    "        sampling_ratio: ratio of minority to majority class\n",
    "        use_SMOTE: boolean for enabling SMOTE (overrides undersample)\n",
    "        \n",
    "    Returns:\n",
    "        A pipeline that will handle under/over sampling without the prior data leakage errors\n",
    "    \"\"\"\n",
    "    # All sampling methods use the same arguments, so do this to save time\n",
    "    kwargs = {'sampling_strategy':sampling_ratio, 'random_state': random_state}\n",
    "    if use_SMOTE:\n",
    "        sampler = SMOTE(**kwargs)\n",
    "    elif undersample:\n",
    "        sampler = RandomUnderSampler(**kwargs)\n",
    "    else:\n",
    "        sampler = RandomOverSampler(**kwargs)\n",
    "    return Pipeline(steps=[('sampler', sampler), ('model', model)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define algorithms and hyperparameter grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Create different models with different hyperparameter grids\n",
    "######################################################\n",
    "seed = 42\n",
    "models = []\n",
    "\n",
    "# The first item in the tuple is the name of the algorithm\n",
    "# The second item is the estimator object itself\n",
    "# The third item is the param grid\n",
    "\n",
    "models.append(('DecisionTree', DecisionTreeClassifier(random_state=seed), {\n",
    "                        'criterion': ['gini','entropy'],\n",
    "                        'min_samples_split': range(0, 21, 7),\n",
    "                        'max_depth': range(6, 21, 5)\n",
    "                    }))\n",
    "\n",
    "models.append(('RandomForest', \n",
    "               RandomForestClassifier(random_state=seed),\n",
    "                    {\n",
    "                        'criterion': ['gini','entropy'],\n",
    "                        'n_estimators': range(100, 301, 100),\n",
    "                        'max_features': ['auto', 'log2'],\n",
    "                        'max_depth': list(range(2, 11, 5))\n",
    "                    }))\n",
    "\n",
    "# models.append(('LogisticRegression', \n",
    "#                LogisticRegression(random_state=seed), \n",
    "#                {'penalty': ['l2', 'elasticnet', 'none'],'C': np.logspace(-4, 6, num=5)}))\n",
    "\n",
    "# models.append(('SupportVectorMachine', SVC(gamma='auto'), \n",
    "#                {'C': np.logspace(-4, 6, num=5), 'gamma': [0.001, 0.0001], 'kernel': ['rbf', 'linear']}\n",
    "#               ))\n",
    "\n",
    "models.append(('PassiveAggressive', \n",
    "               PassiveAggressiveClassifier(random_state=seed, n_jobs=-1), \n",
    "               {'C': np.logspace(-4, 6, num=5), 'loss': ['hinge', 'squared_hinge']}))\n",
    "\n",
    "\n",
    "models.append(('AdaBoost', AdaBoostClassifier(random_state=seed), \n",
    "               {'n_estimators': range(200, 1001, 400), 'learning_rate':[0.001, 0.01]}))\n",
    "\n",
    "models.append(('MultiLayerPerceptron', \n",
    "               MLPClassifier(random_state=seed, max_iter=300),\n",
    "            {'hidden_layer_sizes': [(50,50), (100,50), (100,)],\n",
    "            'activation': ['relu', 'tanh'],\n",
    "            'solver': ['sgd', 'adam'],\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.05],\n",
    "            'learning_rate': ['adaptive', 'constant']}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(X, y, cv=10, metrics=[\n",
    "    'mean_test_balanced_accuracy', 'mean_test_f1', \n",
    "    'mean_test_precision', 'mean_test_recall',\n",
    "    'mean_test_accuracy', 'mean_train_accuracy']):\n",
    "    \n",
    "    \"\"\"\n",
    "    Runs a grid search over all the models in the models variable for the given X and y dataset.\n",
    "    This produces a cross-validation and gathers some useful metrics.\n",
    "    \n",
    "    Args:\n",
    "        X: the input training data of shape (n_samples, n_features)\n",
    "        y: the vector of labels of shape (n_samples,) or (n_samples, n_targets)\n",
    "        cv: int, cross-validation generator or an iterable, Determines the cross-validation splitting strategy\n",
    "        metrics: list of metrics to gather, from https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "                the first argument of this is used as the refit parameter\n",
    "    Returns:\n",
    "        A dataframe containing the parameters of the best fit model for each model and sampling type\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # Make raw_metrics a list of the unique metrics (f1, accuracy, etc) without the \"mean_test_\" prefix\n",
    "    temp_metrics = [re.sub(r'\\w+?_\\w+?_', '', metric) for metric in metrics]\n",
    "    raw_metrics = []\n",
    "    for metric in temp_metrics:\n",
    "        if metric not in raw_metrics:\n",
    "            raw_metrics.append(metric)\n",
    "    \n",
    "    # iterate over every model in the models list\n",
    "    for model_name, model, params in models:\n",
    "        \n",
    "        # modify the param keys because the pipeline changes some names\n",
    "        cv_params = {f'model__{key}': value for key, value in params.items()}\n",
    "        \n",
    "        # also iterate over each sampling type\n",
    "        for sampling_name, under, smote in [\n",
    "            ('under', True, False), ('over', False, False), ('smote', False, True)]:\n",
    "            \n",
    "            # create a resampling pipeline object\n",
    "            pipeline = make_model_pipeline(model, undersample=under, use_SMOTE=smote)\n",
    "            \n",
    "            # run gridsearch \n",
    "            gscv = GridSearchCV(\n",
    "                pipeline, param_grid=cv_params, cv=cv, \n",
    "                scoring=raw_metrics,\n",
    "                verbose=1, n_jobs=1,\n",
    "                return_train_score=True, refit=raw_metrics[0])\n",
    "            gscv.fit(X, y)\n",
    "\n",
    "            # find and store the best performing parameters\n",
    "            row = {'Name':f'{model_name} {sampling_name}',\n",
    "                   'Params':gscv.best_params_}\n",
    "            results, ind = gscv.cv_results_, gscv.best_index_\n",
    "            \n",
    "            for metric in metrics:\n",
    "                row[metric[5:]] = results[metric][ind]\n",
    "                print(model_name, sampling_name, metric[5:], results[metric][ind])\n",
    "            data.append(row)\n",
    "            \n",
    "            print()\n",
    "        print()\n",
    "        \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to simplify running the parameter searches\n",
    "\n",
    "def run_search(df, score_name, X, prefix=''):\n",
    "    Y = df[[score_name+'_score']].values[:, 0].astype('float')\n",
    "    print(len(df), 'cases |', len(Y), 'codes')\n",
    "    params = gridsearch(X, Y)\n",
    "    params.to_csv(logs+f'{prefix}{score_name}_grid_{str(thisday)}.csv', index=False)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814 cases | 814 codes\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree under test_balanced_accuracy 0.6659004768160366\n",
      "DecisionTree under test_f1 0.7364177482387059\n",
      "DecisionTree under test_precision 0.7564161692866013\n",
      "DecisionTree under test_recall 0.7277149321266968\n",
      "DecisionTree under test_accuracy 0.6818428184281843\n",
      "DecisionTree under train_accuracy 0.89776090473315\n",
      "\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree over test_balanced_accuracy 0.7027039848197344\n",
      "DecisionTree over test_f1 0.8113362042820518\n",
      "DecisionTree over test_precision 0.7542862698228431\n",
      "DecisionTree over test_recall 0.8941176470588236\n",
      "DecisionTree over test_accuracy 0.7517765733212887\n",
      "DecisionTree over train_accuracy 0.9473134211526849\n",
      "\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree smote test_balanced_accuracy 0.7000474383301707\n",
      "DecisionTree smote test_f1 0.8039462310821499\n",
      "DecisionTree smote test_precision 0.7507399537154517\n",
      "DecisionTree smote test_recall 0.8823529411764707\n",
      "DecisionTree smote test_accuracy 0.7468383017163505\n",
      "DecisionTree smote train_accuracy 0.9505872639575366\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest under test_balanced_accuracy 0.6966978056731378\n",
      "RandomForest under test_f1 0.7550724698676474\n",
      "RandomForest under test_precision 0.7857095331125941\n",
      "RandomForest under test_recall 0.7432880844645551\n",
      "RandomForest under test_accuracy 0.7088979223125565\n",
      "RandomForest under train_accuracy 0.8962592907357294\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest over test_balanced_accuracy 0.70662871600253\n",
      "RandomForest over test_f1 0.8135439836004524\n",
      "RandomForest over test_precision 0.7621371242269092\n",
      "RandomForest over test_recall 0.8941176470588236\n",
      "RandomForest over test_accuracy 0.7544414333032219\n",
      "RandomForest over train_accuracy 0.9541369400398094\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest smote test_balanced_accuracy 0.7493801391524353\n",
      "RandomForest smote test_f1 0.8255983822682076\n",
      "RandomForest smote test_precision 0.8084642391928387\n",
      "RandomForest smote test_recall 0.8705882352941176\n",
      "RandomForest smote test_accuracy 0.7802469135802469\n",
      "RandomForest smote train_accuracy 0.9505880094528809\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive under test_balanced_accuracy 0.5665941711672262\n",
      "PassiveAggressive under test_f1 0.5189882373705437\n",
      "PassiveAggressive under test_precision 0.6826447057777203\n",
      "PassiveAggressive under test_recall 0.5195324283559577\n",
      "PassiveAggressive under test_accuracy 0.5528003613369467\n",
      "PassiveAggressive under train_accuracy 0.6075742326989169\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive over test_balanced_accuracy 0.5595500656838418\n",
      "PassiveAggressive over test_f1 0.6043262618825525\n",
      "PassiveAggressive over test_precision 0.6950709690991022\n",
      "PassiveAggressive over test_recall 0.6100678733031674\n",
      "PassiveAggressive over test_accuracy 0.5723878349894609\n",
      "PassiveAggressive over train_accuracy 0.6743355772743199\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive smote test_balanced_accuracy 0.5685193159149516\n",
      "PassiveAggressive smote test_f1 0.5842111878882411\n",
      "PassiveAggressive smote test_precision 0.7127910962731141\n",
      "PassiveAggressive smote test_recall 0.6227375565610859\n",
      "PassiveAggressive smote test_accuracy 0.580788919000301\n",
      "PassiveAggressive smote train_accuracy 0.6290236247474634\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost under test_balanced_accuracy 0.5794830438378826\n",
      "AdaBoost under test_f1 0.6622251111339961\n",
      "AdaBoost under test_precision 0.6888409358316685\n",
      "AdaBoost under test_recall 0.6435897435897436\n",
      "AdaBoost under test_accuracy 0.5959048479373682\n",
      "AdaBoost under train_accuracy 0.7708121799029365\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost over test_balanced_accuracy 0.5975892813701162\n",
      "AdaBoost over test_f1 0.6968165396231715\n",
      "AdaBoost over test_precision 0.6965207442208575\n",
      "AdaBoost over test_recall 0.7061463046757165\n",
      "AdaBoost over test_accuracy 0.6254441433303222\n",
      "AdaBoost over train_accuracy 0.8053507928342988\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost smote test_balanced_accuracy 0.5991013477351238\n",
      "AdaBoost smote test_f1 0.6865485317841971\n",
      "AdaBoost smote test_precision 0.7018741431773152\n",
      "AdaBoost smote test_recall 0.6825037707390649\n",
      "AdaBoost smote test_accuracy 0.620460704607046\n",
      "AdaBoost smote train_accuracy 0.7880150440960496\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron under test_balanced_accuracy 0.671469980051574\n",
      "MultiLayerPerceptron under test_f1 0.7472639406003427\n",
      "MultiLayerPerceptron under test_precision 0.7568943832807711\n",
      "MultiLayerPerceptron under test_recall 0.7550904977375567\n",
      "MultiLayerPerceptron under test_accuracy 0.6929238181270702\n",
      "MultiLayerPerceptron under train_accuracy 0.8923038788122767\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron over test_balanced_accuracy 0.6890607210626185\n",
      "MultiLayerPerceptron over test_f1 0.8058149342461579\n",
      "MultiLayerPerceptron over test_precision 0.7455076452019821\n",
      "MultiLayerPerceptron over test_recall 0.8960784313725491\n",
      "MultiLayerPerceptron over test_accuracy 0.7419753086419754\n",
      "MultiLayerPerceptron over train_accuracy 0.9530455348556348\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron smote test_balanced_accuracy 0.6967615433270083\n",
      "MultiLayerPerceptron smote test_f1 0.8098419649102633\n",
      "MultiLayerPerceptron smote test_precision 0.7485262886756145\n",
      "MultiLayerPerceptron smote test_recall 0.8980392156862745\n",
      "MultiLayerPerceptron smote test_accuracy 0.7481330924420355\n",
      "MultiLayerPerceptron smote train_accuracy 0.9522271673413398\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Params</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree under</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.681843</td>\n",
       "      <td>0.665900</td>\n",
       "      <td>0.736418</td>\n",
       "      <td>0.756416</td>\n",
       "      <td>0.727715</td>\n",
       "      <td>0.897761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree over</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.751777</td>\n",
       "      <td>0.702704</td>\n",
       "      <td>0.811336</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.947313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree smote</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.746838</td>\n",
       "      <td>0.700047</td>\n",
       "      <td>0.803946</td>\n",
       "      <td>0.750740</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.950587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest under</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.708898</td>\n",
       "      <td>0.696698</td>\n",
       "      <td>0.755072</td>\n",
       "      <td>0.785710</td>\n",
       "      <td>0.743288</td>\n",
       "      <td>0.896259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest over</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.754441</td>\n",
       "      <td>0.706629</td>\n",
       "      <td>0.813544</td>\n",
       "      <td>0.762137</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.954137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest smote</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.780247</td>\n",
       "      <td>0.749380</td>\n",
       "      <td>0.825598</td>\n",
       "      <td>0.808464</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.950588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PassiveAggressive under</td>\n",
       "      <td>{'model__C': 3162.2776601683795, 'model__loss'...</td>\n",
       "      <td>0.552800</td>\n",
       "      <td>0.566594</td>\n",
       "      <td>0.518988</td>\n",
       "      <td>0.682645</td>\n",
       "      <td>0.519532</td>\n",
       "      <td>0.607574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressive over</td>\n",
       "      <td>{'model__C': 0.03162277660168379, 'model__loss...</td>\n",
       "      <td>0.572388</td>\n",
       "      <td>0.559550</td>\n",
       "      <td>0.604326</td>\n",
       "      <td>0.695071</td>\n",
       "      <td>0.610068</td>\n",
       "      <td>0.674336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PassiveAggressive smote</td>\n",
       "      <td>{'model__C': 10.0, 'model__loss': 'squared_hin...</td>\n",
       "      <td>0.580789</td>\n",
       "      <td>0.568519</td>\n",
       "      <td>0.584211</td>\n",
       "      <td>0.712791</td>\n",
       "      <td>0.622738</td>\n",
       "      <td>0.629024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost under</td>\n",
       "      <td>{'model__learning_rate': 0.01, 'model__n_estim...</td>\n",
       "      <td>0.595905</td>\n",
       "      <td>0.579483</td>\n",
       "      <td>0.662225</td>\n",
       "      <td>0.688841</td>\n",
       "      <td>0.643590</td>\n",
       "      <td>0.770812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost over</td>\n",
       "      <td>{'model__learning_rate': 0.01, 'model__n_estim...</td>\n",
       "      <td>0.625444</td>\n",
       "      <td>0.597589</td>\n",
       "      <td>0.696817</td>\n",
       "      <td>0.696521</td>\n",
       "      <td>0.706146</td>\n",
       "      <td>0.805351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost smote</td>\n",
       "      <td>{'model__learning_rate': 0.01, 'model__n_estim...</td>\n",
       "      <td>0.620461</td>\n",
       "      <td>0.599101</td>\n",
       "      <td>0.686549</td>\n",
       "      <td>0.701874</td>\n",
       "      <td>0.682504</td>\n",
       "      <td>0.788015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MultiLayerPerceptron under</td>\n",
       "      <td>{'model__activation': 'relu', 'model__alpha': ...</td>\n",
       "      <td>0.692924</td>\n",
       "      <td>0.671470</td>\n",
       "      <td>0.747264</td>\n",
       "      <td>0.756894</td>\n",
       "      <td>0.755090</td>\n",
       "      <td>0.892304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MultiLayerPerceptron over</td>\n",
       "      <td>{'model__activation': 'relu', 'model__alpha': ...</td>\n",
       "      <td>0.741975</td>\n",
       "      <td>0.689061</td>\n",
       "      <td>0.805815</td>\n",
       "      <td>0.745508</td>\n",
       "      <td>0.896078</td>\n",
       "      <td>0.953046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MultiLayerPerceptron smote</td>\n",
       "      <td>{'model__activation': 'relu', 'model__alpha': ...</td>\n",
       "      <td>0.748133</td>\n",
       "      <td>0.696762</td>\n",
       "      <td>0.809842</td>\n",
       "      <td>0.748526</td>\n",
       "      <td>0.898039</td>\n",
       "      <td>0.952227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  \\\n",
       "0           DecisionTree under   \n",
       "1            DecisionTree over   \n",
       "2           DecisionTree smote   \n",
       "3           RandomForest under   \n",
       "4            RandomForest over   \n",
       "5           RandomForest smote   \n",
       "6      PassiveAggressive under   \n",
       "7       PassiveAggressive over   \n",
       "8      PassiveAggressive smote   \n",
       "9               AdaBoost under   \n",
       "10               AdaBoost over   \n",
       "11              AdaBoost smote   \n",
       "12  MultiLayerPerceptron under   \n",
       "13   MultiLayerPerceptron over   \n",
       "14  MultiLayerPerceptron smote   \n",
       "\n",
       "                                               Params  test_accuracy  \\\n",
       "0   {'model__criterion': 'gini', 'model__max_depth...       0.681843   \n",
       "1   {'model__criterion': 'entropy', 'model__max_de...       0.751777   \n",
       "2   {'model__criterion': 'gini', 'model__max_depth...       0.746838   \n",
       "3   {'model__criterion': 'entropy', 'model__max_de...       0.708898   \n",
       "4   {'model__criterion': 'gini', 'model__max_depth...       0.754441   \n",
       "5   {'model__criterion': 'gini', 'model__max_depth...       0.780247   \n",
       "6   {'model__C': 3162.2776601683795, 'model__loss'...       0.552800   \n",
       "7   {'model__C': 0.03162277660168379, 'model__loss...       0.572388   \n",
       "8   {'model__C': 10.0, 'model__loss': 'squared_hin...       0.580789   \n",
       "9   {'model__learning_rate': 0.01, 'model__n_estim...       0.595905   \n",
       "10  {'model__learning_rate': 0.01, 'model__n_estim...       0.625444   \n",
       "11  {'model__learning_rate': 0.01, 'model__n_estim...       0.620461   \n",
       "12  {'model__activation': 'relu', 'model__alpha': ...       0.692924   \n",
       "13  {'model__activation': 'relu', 'model__alpha': ...       0.741975   \n",
       "14  {'model__activation': 'relu', 'model__alpha': ...       0.748133   \n",
       "\n",
       "    test_balanced_accuracy   test_f1  test_precision  test_recall  \\\n",
       "0                 0.665900  0.736418        0.756416     0.727715   \n",
       "1                 0.702704  0.811336        0.754286     0.894118   \n",
       "2                 0.700047  0.803946        0.750740     0.882353   \n",
       "3                 0.696698  0.755072        0.785710     0.743288   \n",
       "4                 0.706629  0.813544        0.762137     0.894118   \n",
       "5                 0.749380  0.825598        0.808464     0.870588   \n",
       "6                 0.566594  0.518988        0.682645     0.519532   \n",
       "7                 0.559550  0.604326        0.695071     0.610068   \n",
       "8                 0.568519  0.584211        0.712791     0.622738   \n",
       "9                 0.579483  0.662225        0.688841     0.643590   \n",
       "10                0.597589  0.696817        0.696521     0.706146   \n",
       "11                0.599101  0.686549        0.701874     0.682504   \n",
       "12                0.671470  0.747264        0.756894     0.755090   \n",
       "13                0.689061  0.805815        0.745508     0.896078   \n",
       "14                0.696762  0.809842        0.748526     0.898039   \n",
       "\n",
       "    train_accuracy  \n",
       "0         0.897761  \n",
       "1         0.947313  \n",
       "2         0.950587  \n",
       "3         0.896259  \n",
       "4         0.954137  \n",
       "5         0.950588  \n",
       "6         0.607574  \n",
       "7         0.674336  \n",
       "8         0.629024  \n",
       "9         0.770812  \n",
       "10        0.805351  \n",
       "11        0.788015  \n",
       "12        0.892304  \n",
       "13        0.953046  \n",
       "14        0.952227  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_search(orgs_df, 'orgs', X_orgs, 'ave_embed_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709 cases | 709 codes\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree under test_balanced_accuracy 0.5248448581560284\n",
      "DecisionTree under test_f1 0.41683977493546004\n",
      "DecisionTree under test_precision 0.3511300238464924\n",
      "DecisionTree under test_recall 0.5208333333333333\n",
      "DecisionTree under test_accuracy 0.526297786720322\n",
      "DecisionTree under train_accuracy 0.7878022576419856\n",
      "\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree over test_balanced_accuracy 0.5315554656182548\n",
      "DecisionTree over test_f1 0.39208244522956354\n",
      "DecisionTree over test_precision 0.37503928246392093\n",
      "DecisionTree over test_recall 0.4182971014492754\n",
      "DecisionTree over test_accuracy 0.5699195171026157\n",
      "DecisionTree over train_accuracy 0.9612899269528702\n",
      "\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree smote test_balanced_accuracy 0.5547997610237434\n",
      "DecisionTree smote test_f1 0.42712080710960887\n",
      "DecisionTree smote test_precision 0.38808364815261365\n",
      "DecisionTree smote test_recall 0.4782608695652174\n",
      "DecisionTree smote test_accuracy 0.5811066398390341\n",
      "DecisionTree smote train_accuracy 0.9424880176215776\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest under test_balanced_accuracy 0.5317761332099907\n",
      "RandomForest under test_f1 0.4198242470624586\n",
      "RandomForest under test_precision 0.3598833224658652\n",
      "RandomForest under test_recall 0.5077898550724638\n",
      "RandomForest under test_accuracy 0.5402615694164988\n",
      "RandomForest under train_accuracy 0.7088230532621014\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest over test_balanced_accuracy 0.5272596746839346\n",
      "RandomForest over test_f1 0.2952898987607234\n",
      "RandomForest over test_precision 0.3881691968872275\n",
      "RandomForest over test_recall 0.24365942028985507\n",
      "RandomForest over test_accuracy 0.6234406438631791\n",
      "RandomForest over train_accuracy 0.9918507562266669\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest smote test_balanced_accuracy 0.5310505319148937\n",
      "RandomForest smote test_f1 0.35314695155120684\n",
      "RandomForest smote test_precision 0.3842401366319024\n",
      "RandomForest smote test_recall 0.33749999999999997\n",
      "RandomForest smote test_accuracy 0.596579476861167\n",
      "RandomForest smote train_accuracy 0.9857383941405311\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive under test_balanced_accuracy 0.5232067144619179\n",
      "PassiveAggressive under test_f1 0.40685662922503807\n",
      "PassiveAggressive under test_precision 0.42371712603434303\n",
      "PassiveAggressive under test_recall 0.7001811594202898\n",
      "PassiveAggressive under test_accuracy 0.46102615694164983\n",
      "PassiveAggressive under train_accuracy 0.5071491996212735\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive over test_balanced_accuracy 0.5329719781066913\n",
      "PassiveAggressive over test_f1 0.34672723402151684\n",
      "PassiveAggressive over test_precision 0.3610735849123972\n",
      "PassiveAggressive over test_recall 0.48061594202898555\n",
      "PassiveAggressive over test_accuracy 0.5497786720321931\n",
      "PassiveAggressive over train_accuracy 0.646329001525699\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive smote test_balanced_accuracy 0.524106729879741\n",
      "PassiveAggressive smote test_f1 0.33234656362048376\n",
      "PassiveAggressive smote test_precision 0.3546973123866577\n",
      "PassiveAggressive smote test_recall 0.3722826086956522\n",
      "PassiveAggressive smote test_accuracy 0.578128772635815\n",
      "PassiveAggressive smote train_accuracy 0.6850079228418229\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost under test_balanced_accuracy 0.5492213999383286\n",
      "AdaBoost under test_f1 0.42465151281291247\n",
      "AdaBoost under test_precision 0.3796958483893797\n",
      "AdaBoost under test_recall 0.5018115942028986\n",
      "AdaBoost under test_accuracy 0.5642857142857143\n",
      "AdaBoost under train_accuracy 0.6237219205164809\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost over test_balanced_accuracy 0.5068156413814369\n",
      "AdaBoost over test_f1 0.33919006005450575\n",
      "AdaBoost over test_precision 0.3322152081352655\n",
      "AdaBoost over test_recall 0.4094202898550724\n",
      "AdaBoost over test_accuracy 0.5402615694164989\n",
      "AdaBoost over train_accuracy 0.6114996492364146\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost smote test_balanced_accuracy 0.5170058587727413\n",
      "AdaBoost smote test_f1 0.39418130610805957\n",
      "AdaBoost smote test_precision 0.3505626068406936\n",
      "AdaBoost smote test_recall 0.45271739130434774\n",
      "AdaBoost smote test_accuracy 0.5388329979879275\n",
      "AdaBoost smote train_accuracy 0.754896218130798\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron under test_balanced_accuracy 0.5444977644156644\n",
      "MultiLayerPerceptron under test_f1 0.44568551872903395\n",
      "MultiLayerPerceptron under test_precision 0.3660206446038582\n",
      "MultiLayerPerceptron under test_recall 0.5994565217391303\n",
      "MultiLayerPerceptron under test_accuracy 0.5275653923541246\n",
      "MultiLayerPerceptron under train_accuracy 0.6439310541058962\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron over test_balanced_accuracy 0.5383768886833179\n",
      "MultiLayerPerceptron over test_f1 0.3829426003078394\n",
      "MultiLayerPerceptron over test_precision 0.36775272972641393\n",
      "MultiLayerPerceptron over test_recall 0.419927536231884\n",
      "MultiLayerPerceptron over test_accuracy 0.5782897384305834\n",
      "MultiLayerPerceptron over train_accuracy 0.7790373379251475\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron smote test_balanced_accuracy 0.5329151248843663\n",
      "MultiLayerPerceptron smote test_f1 0.40890892790416605\n",
      "MultiLayerPerceptron smote test_precision 0.3563190157854649\n",
      "MultiLayerPerceptron smote test_recall 0.5023550724637682\n",
      "MultiLayerPerceptron smote test_accuracy 0.5445472837022134\n",
      "MultiLayerPerceptron smote train_accuracy 0.7254242277068892\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Params</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree under</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.526298</td>\n",
       "      <td>0.524845</td>\n",
       "      <td>0.416840</td>\n",
       "      <td>0.351130</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.787802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree over</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.569920</td>\n",
       "      <td>0.531555</td>\n",
       "      <td>0.392082</td>\n",
       "      <td>0.375039</td>\n",
       "      <td>0.418297</td>\n",
       "      <td>0.961290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree smote</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.581107</td>\n",
       "      <td>0.554800</td>\n",
       "      <td>0.427121</td>\n",
       "      <td>0.388084</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.942488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest under</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.540262</td>\n",
       "      <td>0.531776</td>\n",
       "      <td>0.419824</td>\n",
       "      <td>0.359883</td>\n",
       "      <td>0.507790</td>\n",
       "      <td>0.708823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest over</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.623441</td>\n",
       "      <td>0.527260</td>\n",
       "      <td>0.295290</td>\n",
       "      <td>0.388169</td>\n",
       "      <td>0.243659</td>\n",
       "      <td>0.991851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest smote</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.596579</td>\n",
       "      <td>0.531051</td>\n",
       "      <td>0.353147</td>\n",
       "      <td>0.384240</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.985738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PassiveAggressive under</td>\n",
       "      <td>{'model__C': 3162.2776601683795, 'model__loss'...</td>\n",
       "      <td>0.461026</td>\n",
       "      <td>0.523207</td>\n",
       "      <td>0.406857</td>\n",
       "      <td>0.423717</td>\n",
       "      <td>0.700181</td>\n",
       "      <td>0.507149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressive over</td>\n",
       "      <td>{'model__C': 3162.2776601683795, 'model__loss'...</td>\n",
       "      <td>0.549779</td>\n",
       "      <td>0.532972</td>\n",
       "      <td>0.346727</td>\n",
       "      <td>0.361074</td>\n",
       "      <td>0.480616</td>\n",
       "      <td>0.646329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PassiveAggressive smote</td>\n",
       "      <td>{'model__C': 0.03162277660168379, 'model__loss...</td>\n",
       "      <td>0.578129</td>\n",
       "      <td>0.524107</td>\n",
       "      <td>0.332347</td>\n",
       "      <td>0.354697</td>\n",
       "      <td>0.372283</td>\n",
       "      <td>0.685008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost under</td>\n",
       "      <td>{'model__learning_rate': 0.001, 'model__n_esti...</td>\n",
       "      <td>0.564286</td>\n",
       "      <td>0.549221</td>\n",
       "      <td>0.424652</td>\n",
       "      <td>0.379696</td>\n",
       "      <td>0.501812</td>\n",
       "      <td>0.623722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost over</td>\n",
       "      <td>{'model__learning_rate': 0.001, 'model__n_esti...</td>\n",
       "      <td>0.540262</td>\n",
       "      <td>0.506816</td>\n",
       "      <td>0.339190</td>\n",
       "      <td>0.332215</td>\n",
       "      <td>0.409420</td>\n",
       "      <td>0.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost smote</td>\n",
       "      <td>{'model__learning_rate': 0.01, 'model__n_estim...</td>\n",
       "      <td>0.538833</td>\n",
       "      <td>0.517006</td>\n",
       "      <td>0.394181</td>\n",
       "      <td>0.350563</td>\n",
       "      <td>0.452717</td>\n",
       "      <td>0.754896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MultiLayerPerceptron under</td>\n",
       "      <td>{'model__activation': 'tanh', 'model__alpha': ...</td>\n",
       "      <td>0.527565</td>\n",
       "      <td>0.544498</td>\n",
       "      <td>0.445686</td>\n",
       "      <td>0.366021</td>\n",
       "      <td>0.599457</td>\n",
       "      <td>0.643931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MultiLayerPerceptron over</td>\n",
       "      <td>{'model__activation': 'tanh', 'model__alpha': ...</td>\n",
       "      <td>0.578290</td>\n",
       "      <td>0.538377</td>\n",
       "      <td>0.382943</td>\n",
       "      <td>0.367753</td>\n",
       "      <td>0.419928</td>\n",
       "      <td>0.779037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MultiLayerPerceptron smote</td>\n",
       "      <td>{'model__activation': 'tanh', 'model__alpha': ...</td>\n",
       "      <td>0.544547</td>\n",
       "      <td>0.532915</td>\n",
       "      <td>0.408909</td>\n",
       "      <td>0.356319</td>\n",
       "      <td>0.502355</td>\n",
       "      <td>0.725424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  \\\n",
       "0           DecisionTree under   \n",
       "1            DecisionTree over   \n",
       "2           DecisionTree smote   \n",
       "3           RandomForest under   \n",
       "4            RandomForest over   \n",
       "5           RandomForest smote   \n",
       "6      PassiveAggressive under   \n",
       "7       PassiveAggressive over   \n",
       "8      PassiveAggressive smote   \n",
       "9               AdaBoost under   \n",
       "10               AdaBoost over   \n",
       "11              AdaBoost smote   \n",
       "12  MultiLayerPerceptron under   \n",
       "13   MultiLayerPerceptron over   \n",
       "14  MultiLayerPerceptron smote   \n",
       "\n",
       "                                               Params  test_accuracy  \\\n",
       "0   {'model__criterion': 'entropy', 'model__max_de...       0.526298   \n",
       "1   {'model__criterion': 'gini', 'model__max_depth...       0.569920   \n",
       "2   {'model__criterion': 'gini', 'model__max_depth...       0.581107   \n",
       "3   {'model__criterion': 'entropy', 'model__max_de...       0.540262   \n",
       "4   {'model__criterion': 'entropy', 'model__max_de...       0.623441   \n",
       "5   {'model__criterion': 'gini', 'model__max_depth...       0.596579   \n",
       "6   {'model__C': 3162.2776601683795, 'model__loss'...       0.461026   \n",
       "7   {'model__C': 3162.2776601683795, 'model__loss'...       0.549779   \n",
       "8   {'model__C': 0.03162277660168379, 'model__loss...       0.578129   \n",
       "9   {'model__learning_rate': 0.001, 'model__n_esti...       0.564286   \n",
       "10  {'model__learning_rate': 0.001, 'model__n_esti...       0.540262   \n",
       "11  {'model__learning_rate': 0.01, 'model__n_estim...       0.538833   \n",
       "12  {'model__activation': 'tanh', 'model__alpha': ...       0.527565   \n",
       "13  {'model__activation': 'tanh', 'model__alpha': ...       0.578290   \n",
       "14  {'model__activation': 'tanh', 'model__alpha': ...       0.544547   \n",
       "\n",
       "    test_balanced_accuracy   test_f1  test_precision  test_recall  \\\n",
       "0                 0.524845  0.416840        0.351130     0.520833   \n",
       "1                 0.531555  0.392082        0.375039     0.418297   \n",
       "2                 0.554800  0.427121        0.388084     0.478261   \n",
       "3                 0.531776  0.419824        0.359883     0.507790   \n",
       "4                 0.527260  0.295290        0.388169     0.243659   \n",
       "5                 0.531051  0.353147        0.384240     0.337500   \n",
       "6                 0.523207  0.406857        0.423717     0.700181   \n",
       "7                 0.532972  0.346727        0.361074     0.480616   \n",
       "8                 0.524107  0.332347        0.354697     0.372283   \n",
       "9                 0.549221  0.424652        0.379696     0.501812   \n",
       "10                0.506816  0.339190        0.332215     0.409420   \n",
       "11                0.517006  0.394181        0.350563     0.452717   \n",
       "12                0.544498  0.445686        0.366021     0.599457   \n",
       "13                0.538377  0.382943        0.367753     0.419928   \n",
       "14                0.532915  0.408909        0.356319     0.502355   \n",
       "\n",
       "    train_accuracy  \n",
       "0         0.787802  \n",
       "1         0.961290  \n",
       "2         0.942488  \n",
       "3         0.708823  \n",
       "4         0.991851  \n",
       "5         0.985738  \n",
       "6         0.507149  \n",
       "7         0.646329  \n",
       "8         0.685008  \n",
       "9         0.623722  \n",
       "10        0.611500  \n",
       "11        0.754896  \n",
       "12        0.643931  \n",
       "13        0.779037  \n",
       "14        0.725424  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_search(cult_df, 'cultural', X_cult, 'ave_embed_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707 cases | 707 codes\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree under test_balanced_accuracy 0.5318144499178983\n",
      "DecisionTree under test_f1 0.485673273448416\n",
      "DecisionTree under test_precision 0.4328582065314007\n",
      "DecisionTree under test_recall 0.5588669950738917\n",
      "DecisionTree under test_accuracy 0.5264587525150904\n",
      "DecisionTree under train_accuracy 0.8904581716576325\n",
      "\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree over test_balanced_accuracy 0.5334154351395731\n",
      "DecisionTree over test_f1 0.45369530977339234\n",
      "DecisionTree over test_precision 0.4397617387697174\n",
      "DecisionTree over test_recall 0.4834975369458128\n",
      "DecisionTree over test_accuracy 0.5431589537223339\n",
      "DecisionTree over train_accuracy 0.8035462515920738\n",
      "\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree smote test_balanced_accuracy 0.5308702791461413\n",
      "DecisionTree smote test_f1 0.5018415245206129\n",
      "DecisionTree smote test_precision 0.4380418485273216\n",
      "DecisionTree smote test_recall 0.6022167487684729\n",
      "DecisionTree smote test_accuracy 0.517665995975855\n",
      "DecisionTree smote train_accuracy 0.7417723112467047\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest under test_balanced_accuracy 0.5249384236453201\n",
      "RandomForest under test_f1 0.4792445472533859\n",
      "RandomForest under test_precision 0.426831502894396\n",
      "RandomForest under test_recall 0.5498768472906403\n",
      "RandomForest under test_accuracy 0.520261569416499\n",
      "RandomForest under train_accuracy 0.9055441189538224\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest over test_balanced_accuracy 0.5399425287356323\n",
      "RandomForest over test_f1 0.4516959512852295\n",
      "RandomForest over test_precision 0.4550866785410722\n",
      "RandomForest over test_recall 0.45369458128078816\n",
      "RandomForest over test_accuracy 0.555814889336016\n",
      "RandomForest over train_accuracy 0.7532493113355647\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest smote test_balanced_accuracy 0.5181239737274221\n",
      "RandomForest smote test_f1 0.4492875237226858\n",
      "RandomForest smote test_precision 0.42430652398756363\n",
      "RandomForest smote test_recall 0.48386699507389164\n",
      "RandomForest smote test_accuracy 0.5246680080482897\n",
      "RandomForest smote train_accuracy 0.7444610645419271\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive under test_balanced_accuracy 0.5100985221674877\n",
      "PassiveAggressive under test_f1 0.4785905313131842\n",
      "PassiveAggressive under test_precision 0.4023161398518223\n",
      "PassiveAggressive under test_recall 0.6844827586206896\n",
      "PassiveAggressive under test_accuracy 0.4764386317907444\n",
      "PassiveAggressive under train_accuracy 0.5822867608581895\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive over test_balanced_accuracy 0.5090927750410508\n",
      "PassiveAggressive over test_f1 0.3878821424758755\n",
      "PassiveAggressive over test_precision 0.44050395262003617\n",
      "PassiveAggressive over test_recall 0.5205665024630541\n",
      "PassiveAggressive over test_accuracy 0.5061971830985915\n",
      "PassiveAggressive over train_accuracy 0.6013311710751064\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive smote test_balanced_accuracy 0.5148809523809523\n",
      "PassiveAggressive smote test_f1 0.47035518875148064\n",
      "PassiveAggressive smote test_precision 0.41680208939412805\n",
      "PassiveAggressive smote test_recall 0.5535714285714286\n",
      "PassiveAggressive smote test_accuracy 0.5076861167002014\n",
      "PassiveAggressive smote train_accuracy 0.6168429055221508\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost under test_balanced_accuracy 0.5195402298850575\n",
      "AdaBoost under test_f1 0.4757287910011659\n",
      "AdaBoost under test_precision 0.4234292513531467\n",
      "AdaBoost under test_recall 0.5509852216748768\n",
      "AdaBoost under test_accuracy 0.5133802816901408\n",
      "AdaBoost under train_accuracy 0.7718007957900141\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost over test_balanced_accuracy 0.5181239737274221\n",
      "AdaBoost over test_f1 0.457225980644883\n",
      "AdaBoost over test_precision 0.4225013707366648\n",
      "AdaBoost over test_recall 0.5052955665024631\n",
      "AdaBoost over test_accuracy 0.5204828973843059\n",
      "AdaBoost over train_accuracy 0.6430906469990028\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost smote test_balanced_accuracy 0.5105911330049261\n",
      "AdaBoost smote test_f1 0.4363909968980038\n",
      "AdaBoost smote test_precision 0.4145250534833078\n",
      "AdaBoost smote test_recall 0.464039408866995\n",
      "AdaBoost smote test_accuracy 0.5191750503018108\n",
      "AdaBoost smote train_accuracy 0.7774621604810285\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron under test_balanced_accuracy 0.530008210180624\n",
      "MultiLayerPerceptron under test_f1 0.4520104646682837\n",
      "MultiLayerPerceptron under test_precision 0.4466704382995566\n",
      "MultiLayerPerceptron under test_recall 0.49334975369458134\n",
      "MultiLayerPerceptron under test_accuracy 0.5358752515090542\n",
      "MultiLayerPerceptron under train_accuracy 0.7086477987421383\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron over test_balanced_accuracy 0.5358784893267652\n",
      "MultiLayerPerceptron over test_f1 0.4473536574837237\n",
      "MultiLayerPerceptron over test_precision 0.4442144825537321\n",
      "MultiLayerPerceptron over test_recall 0.46699507389162564\n",
      "MultiLayerPerceptron over test_accuracy 0.5487122736418512\n",
      "MultiLayerPerceptron over train_accuracy 0.7325128600061215\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron smote test_balanced_accuracy 0.5334975369458127\n",
      "MultiLayerPerceptron smote test_f1 0.4513183938158464\n",
      "MultiLayerPerceptron smote test_precision 0.4398721937079215\n",
      "MultiLayerPerceptron smote test_recall 0.48842364532019705\n",
      "MultiLayerPerceptron smote test_accuracy 0.5416700201207243\n",
      "MultiLayerPerceptron smote train_accuracy 0.7152357750066645\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Params</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree under</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.526459</td>\n",
       "      <td>0.531814</td>\n",
       "      <td>0.485673</td>\n",
       "      <td>0.432858</td>\n",
       "      <td>0.558867</td>\n",
       "      <td>0.890458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree over</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.543159</td>\n",
       "      <td>0.533415</td>\n",
       "      <td>0.453695</td>\n",
       "      <td>0.439762</td>\n",
       "      <td>0.483498</td>\n",
       "      <td>0.803546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree smote</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.517666</td>\n",
       "      <td>0.530870</td>\n",
       "      <td>0.501842</td>\n",
       "      <td>0.438042</td>\n",
       "      <td>0.602217</td>\n",
       "      <td>0.741772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest under</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.520262</td>\n",
       "      <td>0.524938</td>\n",
       "      <td>0.479245</td>\n",
       "      <td>0.426832</td>\n",
       "      <td>0.549877</td>\n",
       "      <td>0.905544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest over</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.555815</td>\n",
       "      <td>0.539943</td>\n",
       "      <td>0.451696</td>\n",
       "      <td>0.455087</td>\n",
       "      <td>0.453695</td>\n",
       "      <td>0.753249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest smote</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.524668</td>\n",
       "      <td>0.518124</td>\n",
       "      <td>0.449288</td>\n",
       "      <td>0.424307</td>\n",
       "      <td>0.483867</td>\n",
       "      <td>0.744461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PassiveAggressive under</td>\n",
       "      <td>{'model__C': 1000000.0, 'model__loss': 'hinge'}</td>\n",
       "      <td>0.476439</td>\n",
       "      <td>0.510099</td>\n",
       "      <td>0.478591</td>\n",
       "      <td>0.402316</td>\n",
       "      <td>0.684483</td>\n",
       "      <td>0.582287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressive over</td>\n",
       "      <td>{'model__C': 3162.2776601683795, 'model__loss'...</td>\n",
       "      <td>0.506197</td>\n",
       "      <td>0.509093</td>\n",
       "      <td>0.387882</td>\n",
       "      <td>0.440504</td>\n",
       "      <td>0.520567</td>\n",
       "      <td>0.601331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PassiveAggressive smote</td>\n",
       "      <td>{'model__C': 0.03162277660168379, 'model__loss...</td>\n",
       "      <td>0.507686</td>\n",
       "      <td>0.514881</td>\n",
       "      <td>0.470355</td>\n",
       "      <td>0.416802</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.616843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost under</td>\n",
       "      <td>{'model__learning_rate': 0.01, 'model__n_estim...</td>\n",
       "      <td>0.513380</td>\n",
       "      <td>0.519540</td>\n",
       "      <td>0.475729</td>\n",
       "      <td>0.423429</td>\n",
       "      <td>0.550985</td>\n",
       "      <td>0.771801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost over</td>\n",
       "      <td>{'model__learning_rate': 0.001, 'model__n_esti...</td>\n",
       "      <td>0.520483</td>\n",
       "      <td>0.518124</td>\n",
       "      <td>0.457226</td>\n",
       "      <td>0.422501</td>\n",
       "      <td>0.505296</td>\n",
       "      <td>0.643091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost smote</td>\n",
       "      <td>{'model__learning_rate': 0.01, 'model__n_estim...</td>\n",
       "      <td>0.519175</td>\n",
       "      <td>0.510591</td>\n",
       "      <td>0.436391</td>\n",
       "      <td>0.414525</td>\n",
       "      <td>0.464039</td>\n",
       "      <td>0.777462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MultiLayerPerceptron under</td>\n",
       "      <td>{'model__activation': 'tanh', 'model__alpha': ...</td>\n",
       "      <td>0.535875</td>\n",
       "      <td>0.530008</td>\n",
       "      <td>0.452010</td>\n",
       "      <td>0.446670</td>\n",
       "      <td>0.493350</td>\n",
       "      <td>0.708648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MultiLayerPerceptron over</td>\n",
       "      <td>{'model__activation': 'tanh', 'model__alpha': ...</td>\n",
       "      <td>0.548712</td>\n",
       "      <td>0.535878</td>\n",
       "      <td>0.447354</td>\n",
       "      <td>0.444214</td>\n",
       "      <td>0.466995</td>\n",
       "      <td>0.732513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MultiLayerPerceptron smote</td>\n",
       "      <td>{'model__activation': 'tanh', 'model__alpha': ...</td>\n",
       "      <td>0.541670</td>\n",
       "      <td>0.533498</td>\n",
       "      <td>0.451318</td>\n",
       "      <td>0.439872</td>\n",
       "      <td>0.488424</td>\n",
       "      <td>0.715236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  \\\n",
       "0           DecisionTree under   \n",
       "1            DecisionTree over   \n",
       "2           DecisionTree smote   \n",
       "3           RandomForest under   \n",
       "4            RandomForest over   \n",
       "5           RandomForest smote   \n",
       "6      PassiveAggressive under   \n",
       "7       PassiveAggressive over   \n",
       "8      PassiveAggressive smote   \n",
       "9               AdaBoost under   \n",
       "10               AdaBoost over   \n",
       "11              AdaBoost smote   \n",
       "12  MultiLayerPerceptron under   \n",
       "13   MultiLayerPerceptron over   \n",
       "14  MultiLayerPerceptron smote   \n",
       "\n",
       "                                               Params  test_accuracy  \\\n",
       "0   {'model__criterion': 'gini', 'model__max_depth...       0.526459   \n",
       "1   {'model__criterion': 'gini', 'model__max_depth...       0.543159   \n",
       "2   {'model__criterion': 'entropy', 'model__max_de...       0.517666   \n",
       "3   {'model__criterion': 'gini', 'model__max_depth...       0.520262   \n",
       "4   {'model__criterion': 'entropy', 'model__max_de...       0.555815   \n",
       "5   {'model__criterion': 'gini', 'model__max_depth...       0.524668   \n",
       "6     {'model__C': 1000000.0, 'model__loss': 'hinge'}       0.476439   \n",
       "7   {'model__C': 3162.2776601683795, 'model__loss'...       0.506197   \n",
       "8   {'model__C': 0.03162277660168379, 'model__loss...       0.507686   \n",
       "9   {'model__learning_rate': 0.01, 'model__n_estim...       0.513380   \n",
       "10  {'model__learning_rate': 0.001, 'model__n_esti...       0.520483   \n",
       "11  {'model__learning_rate': 0.01, 'model__n_estim...       0.519175   \n",
       "12  {'model__activation': 'tanh', 'model__alpha': ...       0.535875   \n",
       "13  {'model__activation': 'tanh', 'model__alpha': ...       0.548712   \n",
       "14  {'model__activation': 'tanh', 'model__alpha': ...       0.541670   \n",
       "\n",
       "    test_balanced_accuracy   test_f1  test_precision  test_recall  \\\n",
       "0                 0.531814  0.485673        0.432858     0.558867   \n",
       "1                 0.533415  0.453695        0.439762     0.483498   \n",
       "2                 0.530870  0.501842        0.438042     0.602217   \n",
       "3                 0.524938  0.479245        0.426832     0.549877   \n",
       "4                 0.539943  0.451696        0.455087     0.453695   \n",
       "5                 0.518124  0.449288        0.424307     0.483867   \n",
       "6                 0.510099  0.478591        0.402316     0.684483   \n",
       "7                 0.509093  0.387882        0.440504     0.520567   \n",
       "8                 0.514881  0.470355        0.416802     0.553571   \n",
       "9                 0.519540  0.475729        0.423429     0.550985   \n",
       "10                0.518124  0.457226        0.422501     0.505296   \n",
       "11                0.510591  0.436391        0.414525     0.464039   \n",
       "12                0.530008  0.452010        0.446670     0.493350   \n",
       "13                0.535878  0.447354        0.444214     0.466995   \n",
       "14                0.533498  0.451318        0.439872     0.488424   \n",
       "\n",
       "    train_accuracy  \n",
       "0         0.890458  \n",
       "1         0.803546  \n",
       "2         0.741772  \n",
       "3         0.905544  \n",
       "4         0.753249  \n",
       "5         0.744461  \n",
       "6         0.582287  \n",
       "7         0.601331  \n",
       "8         0.616843  \n",
       "9         0.771801  \n",
       "10        0.643091  \n",
       "11        0.777462  \n",
       "12        0.708648  \n",
       "13        0.732513  \n",
       "14        0.715236  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_search(relt_df, 'relational', X_relt, 'ave_embed_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733 cases | 733 codes\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree under test_balanced_accuracy 0.577548690671031\n",
      "DecisionTree under test_f1 0.4949171700101128\n",
      "DecisionTree under test_precision 0.4257698428654783\n",
      "DecisionTree under test_recall 0.5973846153846154\n",
      "DecisionTree under test_accuracy 0.571380970011107\n",
      "DecisionTree under train_accuracy 0.8247728422311124\n",
      "\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree over test_balanced_accuracy 0.536913188761593\n",
      "DecisionTree over test_f1 0.412268574645917\n",
      "DecisionTree over test_precision 0.3888221531671742\n",
      "DecisionTree over test_recall 0.44461538461538463\n",
      "DecisionTree over test_accuracy 0.5647908182154757\n",
      "DecisionTree over train_accuracy 0.8770607440106681\n",
      "\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "DecisionTree smote test_balanced_accuracy 0.540636524822695\n",
      "DecisionTree smote test_f1 0.41114315986107774\n",
      "DecisionTree smote test_precision 0.39028714233078843\n",
      "DecisionTree smote test_recall 0.44200000000000006\n",
      "DecisionTree smote test_accuracy 0.5702332469455756\n",
      "DecisionTree smote train_accuracy 0.9795369476249597\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest under test_balanced_accuracy 0.5691827605019094\n",
      "RandomForest under test_f1 0.48730862477742204\n",
      "RandomForest under test_precision 0.4133660781258035\n",
      "RandomForest under test_recall 0.5972307692307692\n",
      "RandomForest under test_accuracy 0.560625694187338\n",
      "RandomForest under train_accuracy 0.8538685795741943\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest over test_balanced_accuracy 0.5606783278777959\n",
      "RandomForest over test_f1 0.3838329756493847\n",
      "RandomForest over test_precision 0.4605874743255279\n",
      "RandomForest over test_recall 0.3352307692307693\n",
      "RandomForest over test_accuracy 0.6288226582747131\n",
      "RandomForest over train_accuracy 0.9902977422173173\n",
      "\n",
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "RandomForest smote test_balanced_accuracy 0.566204037097654\n",
      "RandomForest smote test_f1 0.44216514292333864\n",
      "RandomForest smote test_precision 0.4323954487402763\n",
      "RandomForest smote test_recall 0.45723076923076933\n",
      "RandomForest smote test_accuracy 0.5988522769344687\n",
      "RandomForest smote train_accuracy 0.9698337701751967\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive under test_balanced_accuracy 0.5411404118930714\n",
      "PassiveAggressive under test_f1 0.40333249612517497\n",
      "PassiveAggressive under test_precision 0.4216243935813607\n",
      "PassiveAggressive under test_recall 0.4670769230769231\n",
      "PassiveAggressive under test_accuracy 0.5617734172528692\n",
      "PassiveAggressive under train_accuracy 0.6628877546328228\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive over test_balanced_accuracy 0.5500681260229132\n",
      "PassiveAggressive over test_f1 0.38761146566448546\n",
      "PassiveAggressive over test_precision 0.4014103214996072\n",
      "PassiveAggressive over test_recall 0.4127692307692308\n",
      "PassiveAggressive over test_accuracy 0.5919844502036282\n",
      "PassiveAggressive over train_accuracy 0.6815089437623579\n",
      "\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "PassiveAggressive smote test_balanced_accuracy 0.563035597381342\n",
      "PassiveAggressive smote test_f1 0.4430606806129195\n",
      "PassiveAggressive smote test_precision 0.41727114356382644\n",
      "PassiveAggressive smote test_recall 0.4912307692307693\n",
      "PassiveAggressive smote test_accuracy 0.5851351351351352\n",
      "PassiveAggressive smote train_accuracy 0.6586418816388467\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost under test_balanced_accuracy 0.5474301009274414\n",
      "AdaBoost under test_f1 0.4677934638532264\n",
      "AdaBoost under test_precision 0.39125308085915583\n",
      "AdaBoost under test_recall 0.5892307692307692\n",
      "AdaBoost under test_accuracy 0.5346723435764532\n",
      "AdaBoost under train_accuracy 0.7151717478272865\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost over test_balanced_accuracy 0.5532558647026733\n",
      "AdaBoost over test_f1 0.43713017663590925\n",
      "AdaBoost over test_precision 0.41585505012229146\n",
      "AdaBoost over test_recall 0.468923076923077\n",
      "AdaBoost over test_accuracy 0.5782487967419475\n",
      "AdaBoost over train_accuracy 0.7958164344507288\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "AdaBoost smote test_balanced_accuracy 0.5697006955810148\n",
      "AdaBoost smote test_f1 0.4991087587661195\n",
      "AdaBoost smote test_precision 0.40592516293002656\n",
      "AdaBoost smote test_recall 0.6610769230769231\n",
      "AdaBoost smote test_accuracy 0.5415957052943353\n",
      "AdaBoost smote train_accuracy 0.5902765898744655\n",
      "\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron under test_balanced_accuracy 0.56627304964539\n",
      "MultiLayerPerceptron under test_f1 0.4713695272879398\n",
      "MultiLayerPerceptron under test_precision 0.4175284549857354\n",
      "MultiLayerPerceptron under test_recall 0.554\n",
      "MultiLayerPerceptron under test_accuracy 0.5700666419844503\n",
      "MultiLayerPerceptron under train_accuracy 0.7186556766450545\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron over test_balanced_accuracy 0.5749386252045826\n",
      "MultiLayerPerceptron over test_f1 0.4712703436998883\n",
      "MultiLayerPerceptron over test_precision 0.42680967323075547\n",
      "MultiLayerPerceptron over test_recall 0.5461538461538462\n",
      "MultiLayerPerceptron over test_accuracy 0.5837282487967419\n",
      "MultiLayerPerceptron over train_accuracy 0.7492794408424152\n",
      "\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n",
      "MultiLayerPerceptron smote test_balanced_accuracy 0.5807392253136934\n",
      "MultiLayerPerceptron smote test_f1 0.4461550083583508\n",
      "MultiLayerPerceptron smote test_precision 0.4624300120972788\n",
      "MultiLayerPerceptron smote test_recall 0.4607692307692308\n",
      "MultiLayerPerceptron smote test_accuracy 0.6163828211773417\n",
      "MultiLayerPerceptron smote train_accuracy 0.7938506460661242\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Params</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree under</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.571381</td>\n",
       "      <td>0.577549</td>\n",
       "      <td>0.494917</td>\n",
       "      <td>0.425770</td>\n",
       "      <td>0.597385</td>\n",
       "      <td>0.824773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree over</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.564791</td>\n",
       "      <td>0.536913</td>\n",
       "      <td>0.412269</td>\n",
       "      <td>0.388822</td>\n",
       "      <td>0.444615</td>\n",
       "      <td>0.877061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree smote</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.570233</td>\n",
       "      <td>0.540637</td>\n",
       "      <td>0.411143</td>\n",
       "      <td>0.390287</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>0.979537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest under</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.560626</td>\n",
       "      <td>0.569183</td>\n",
       "      <td>0.487309</td>\n",
       "      <td>0.413366</td>\n",
       "      <td>0.597231</td>\n",
       "      <td>0.853869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest over</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.628823</td>\n",
       "      <td>0.560678</td>\n",
       "      <td>0.383833</td>\n",
       "      <td>0.460587</td>\n",
       "      <td>0.335231</td>\n",
       "      <td>0.990298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest smote</td>\n",
       "      <td>{'model__criterion': 'entropy', 'model__max_de...</td>\n",
       "      <td>0.598852</td>\n",
       "      <td>0.566204</td>\n",
       "      <td>0.442165</td>\n",
       "      <td>0.432395</td>\n",
       "      <td>0.457231</td>\n",
       "      <td>0.969834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PassiveAggressive under</td>\n",
       "      <td>{'model__C': 0.03162277660168379, 'model__loss...</td>\n",
       "      <td>0.561773</td>\n",
       "      <td>0.541140</td>\n",
       "      <td>0.403332</td>\n",
       "      <td>0.421624</td>\n",
       "      <td>0.467077</td>\n",
       "      <td>0.662888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PassiveAggressive over</td>\n",
       "      <td>{'model__C': 0.03162277660168379, 'model__loss...</td>\n",
       "      <td>0.591984</td>\n",
       "      <td>0.550068</td>\n",
       "      <td>0.387611</td>\n",
       "      <td>0.401410</td>\n",
       "      <td>0.412769</td>\n",
       "      <td>0.681509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PassiveAggressive smote</td>\n",
       "      <td>{'model__C': 0.03162277660168379, 'model__loss...</td>\n",
       "      <td>0.585135</td>\n",
       "      <td>0.563036</td>\n",
       "      <td>0.443061</td>\n",
       "      <td>0.417271</td>\n",
       "      <td>0.491231</td>\n",
       "      <td>0.658642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost under</td>\n",
       "      <td>{'model__learning_rate': 0.01, 'model__n_estim...</td>\n",
       "      <td>0.534672</td>\n",
       "      <td>0.547430</td>\n",
       "      <td>0.467793</td>\n",
       "      <td>0.391253</td>\n",
       "      <td>0.589231</td>\n",
       "      <td>0.715172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost over</td>\n",
       "      <td>{'model__learning_rate': 0.01, 'model__n_estim...</td>\n",
       "      <td>0.578249</td>\n",
       "      <td>0.553256</td>\n",
       "      <td>0.437130</td>\n",
       "      <td>0.415855</td>\n",
       "      <td>0.468923</td>\n",
       "      <td>0.795816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost smote</td>\n",
       "      <td>{'model__learning_rate': 0.001, 'model__n_esti...</td>\n",
       "      <td>0.541596</td>\n",
       "      <td>0.569701</td>\n",
       "      <td>0.499109</td>\n",
       "      <td>0.405925</td>\n",
       "      <td>0.661077</td>\n",
       "      <td>0.590277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MultiLayerPerceptron under</td>\n",
       "      <td>{'model__activation': 'tanh', 'model__alpha': ...</td>\n",
       "      <td>0.570067</td>\n",
       "      <td>0.566273</td>\n",
       "      <td>0.471370</td>\n",
       "      <td>0.417528</td>\n",
       "      <td>0.554000</td>\n",
       "      <td>0.718656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MultiLayerPerceptron over</td>\n",
       "      <td>{'model__activation': 'tanh', 'model__alpha': ...</td>\n",
       "      <td>0.583728</td>\n",
       "      <td>0.574939</td>\n",
       "      <td>0.471270</td>\n",
       "      <td>0.426810</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>0.749279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MultiLayerPerceptron smote</td>\n",
       "      <td>{'model__activation': 'tanh', 'model__alpha': ...</td>\n",
       "      <td>0.616383</td>\n",
       "      <td>0.580739</td>\n",
       "      <td>0.446155</td>\n",
       "      <td>0.462430</td>\n",
       "      <td>0.460769</td>\n",
       "      <td>0.793851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  \\\n",
       "0           DecisionTree under   \n",
       "1            DecisionTree over   \n",
       "2           DecisionTree smote   \n",
       "3           RandomForest under   \n",
       "4            RandomForest over   \n",
       "5           RandomForest smote   \n",
       "6      PassiveAggressive under   \n",
       "7       PassiveAggressive over   \n",
       "8      PassiveAggressive smote   \n",
       "9               AdaBoost under   \n",
       "10               AdaBoost over   \n",
       "11              AdaBoost smote   \n",
       "12  MultiLayerPerceptron under   \n",
       "13   MultiLayerPerceptron over   \n",
       "14  MultiLayerPerceptron smote   \n",
       "\n",
       "                                               Params  test_accuracy  \\\n",
       "0   {'model__criterion': 'gini', 'model__max_depth...       0.571381   \n",
       "1   {'model__criterion': 'entropy', 'model__max_de...       0.564791   \n",
       "2   {'model__criterion': 'gini', 'model__max_depth...       0.570233   \n",
       "3   {'model__criterion': 'entropy', 'model__max_de...       0.560626   \n",
       "4   {'model__criterion': 'entropy', 'model__max_de...       0.628823   \n",
       "5   {'model__criterion': 'entropy', 'model__max_de...       0.598852   \n",
       "6   {'model__C': 0.03162277660168379, 'model__loss...       0.561773   \n",
       "7   {'model__C': 0.03162277660168379, 'model__loss...       0.591984   \n",
       "8   {'model__C': 0.03162277660168379, 'model__loss...       0.585135   \n",
       "9   {'model__learning_rate': 0.01, 'model__n_estim...       0.534672   \n",
       "10  {'model__learning_rate': 0.01, 'model__n_estim...       0.578249   \n",
       "11  {'model__learning_rate': 0.001, 'model__n_esti...       0.541596   \n",
       "12  {'model__activation': 'tanh', 'model__alpha': ...       0.570067   \n",
       "13  {'model__activation': 'tanh', 'model__alpha': ...       0.583728   \n",
       "14  {'model__activation': 'tanh', 'model__alpha': ...       0.616383   \n",
       "\n",
       "    test_balanced_accuracy   test_f1  test_precision  test_recall  \\\n",
       "0                 0.577549  0.494917        0.425770     0.597385   \n",
       "1                 0.536913  0.412269        0.388822     0.444615   \n",
       "2                 0.540637  0.411143        0.390287     0.442000   \n",
       "3                 0.569183  0.487309        0.413366     0.597231   \n",
       "4                 0.560678  0.383833        0.460587     0.335231   \n",
       "5                 0.566204  0.442165        0.432395     0.457231   \n",
       "6                 0.541140  0.403332        0.421624     0.467077   \n",
       "7                 0.550068  0.387611        0.401410     0.412769   \n",
       "8                 0.563036  0.443061        0.417271     0.491231   \n",
       "9                 0.547430  0.467793        0.391253     0.589231   \n",
       "10                0.553256  0.437130        0.415855     0.468923   \n",
       "11                0.569701  0.499109        0.405925     0.661077   \n",
       "12                0.566273  0.471370        0.417528     0.554000   \n",
       "13                0.574939  0.471270        0.426810     0.546154   \n",
       "14                0.580739  0.446155        0.462430     0.460769   \n",
       "\n",
       "    train_accuracy  \n",
       "0         0.824773  \n",
       "1         0.877061  \n",
       "2         0.979537  \n",
       "3         0.853869  \n",
       "4         0.990298  \n",
       "5         0.969834  \n",
       "6         0.662888  \n",
       "7         0.681509  \n",
       "8         0.658642  \n",
       "9         0.715172  \n",
       "10        0.795816  \n",
       "11        0.590277  \n",
       "12        0.718656  \n",
       "13        0.749279  \n",
       "14        0.793851  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_search(demog_df, 'demographic', X_demog, 'ave_embed_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
