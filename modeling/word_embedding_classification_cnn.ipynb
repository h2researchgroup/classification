{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare classification methods for identifying org. science perspectives in JSTOR articles using Word Embeddings\n",
    "## Using grid search and balanced samples from hand-labeled set of articles\n",
    "\n",
    "@author: Thomas Lu, Jaren Haber PhD<br>\n",
    "@coauthors: Prof. Heather Haveman, UC Berkeley; Yoon Sung Hong, Wayfair<br>\n",
    "@contact: Jaren.Haber@georgetown.edu<br>\n",
    "@project: Computational Literature Review of Organizational Scholarship<br>\n",
    "@date: September 2021\n",
    "\n",
    "'''\n",
    "Trains classifiers to predict whether an article is about a given perspective in org. science. To train the classifiers, uses preliminary labeled articles, broken down as follows: \n",
    "Cultural: 105 yes, 209 no\n",
    "Relational: 92 yes, 230 no\n",
    "Demographic: 77 yes, 249 no\n",
    "Compares f1_weighted scores of four model structures using 10-Fold Cross Validation: Logistic regression, SVM, Naive Bayes, and Decision Tree. Oversamples training data to .7 (7:10 minority:majority class).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cult, Y, test_size=0.10, random_state=42)\n",
    "print('original data size: train', X_train.shape, 'test', X_test.shape)\n",
    "\n",
    "def oversample_shuffle(X, y):\n",
    "    ros = RandomOverSampler(random_state=42, sampling_strategy=1.0)\n",
    "    X, y = ros.fit_resample(X, y)\n",
    "    p = np.random.permutation(len(X))\n",
    "    return X[p], y[p]\n",
    "\n",
    "X_train, y_train = oversample_shuffle(X_train, y_train)\n",
    "X_test, y_test = oversample_shuffle(X_test, y_test)\n",
    "print('new data size: train', X_train.shape, 'test', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Import libraries\n",
    "######################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import csv\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, KFold\n",
    "\n",
    "# !pip install imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "import sys; sys.path.insert(0, \"../preprocess/\") # For loading functions from files in other directory\n",
    "from quickpickle import quickpickle_dump, quickpickle_load # custom scripts for quick saving & loading to pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Define filepaths\n",
    "######################################################\n",
    "\n",
    "data_folder = 'classification'\n",
    "folder = 'tlu_test'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "root = str.replace(cwd, f'{folder}/modeling', '')\n",
    "\n",
    "thisday = date.today().strftime(\"%m%d%y\")\n",
    "\n",
    "# Directory for prepared data and trained models: save files here\n",
    "data_fp = root + f'{data_folder}/data/'\n",
    "model_fp = root + f'{folder}/models/'\n",
    "logs = root + f'{folder}/modeling/logs/'\n",
    "\n",
    "w2v_fp = root + 'models_storage/word_embeddings_data/word2vec_phrased_filtered_300d_2020_sept5.bin'\n",
    "\n",
    "# Current article lists\n",
    "article_list_fp = data_fp + 'filtered_length_index.csv' # Filtered index of research articles\n",
    "article_paths_fp = data_fp + 'filtered_length_article_paths.csv' # List of article file paths\n",
    "\n",
    "# Preprocessed training data\n",
    "cult_labeled_fp = data_fp + 'training_cultural_preprocessed_022621.pkl'\n",
    "relt_labeled_fp = data_fp + 'training_relational_preprocessed_022621.pkl'\n",
    "demog_labeled_fp = data_fp + 'training_demographic_preprocessed_022621.pkl'\n",
    "orgs_labeled_fp = data_fp + 'training_orgs_preprocessed_022621.pkl'\n",
    "\n",
    "# Model filepaths\n",
    "cult_model_fp = model_fp + f'classifier_cult_MLP_{str(thisday)}.joblib'\n",
    "relt_model_fp = model_fp + f'classifier_relt_MLP_{str(thisday)}.joblib'\n",
    "demog_model_fp = model_fp + f'classifier_demog_MLP_{str(thisday)}.joblib'\n",
    "orgs_model_fp = model_fp + f'classifier_orgs_MLP_{str(thisday)}.joblib'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the word2vec model, find and set the special token ids\n",
    "\n",
    "w2v_model = KeyedVectors.load(w2v_fp)\n",
    "\n",
    "key2index = w2v_model.wv.key_to_index\n",
    "\n",
    "embedding_dim = 300\n",
    "\n",
    "PAD_IDX = len(key2index)\n",
    "PERIOD_IDX = PAD_IDX + 1\n",
    "UNK_IDX = PAD_IDX + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>orgs_score</th>\n",
       "      <th>edited_filename</th>\n",
       "      <th>article_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[research, note, church_membership, netherlan...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1086_210179</td>\n",
       "      <td>Where Do Interorganizational Networks Come From?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[polish, io_oo, sociological_review, issn, co...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1086_210317</td>\n",
       "      <td>Civil Rights Law at Work: Sex Discrimination a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[article, jjdlbsj, grapliy, compassionate, eg...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1086_231084</td>\n",
       "      <td>Between Markets and Politics: Organizational R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[reply, allison, more, comparing, regression_...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1086_231174</td>\n",
       "      <td>World Society and the Nation‐State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[determinants, spousal, interaction, marital,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1086_382347</td>\n",
       "      <td>Kinship Networks and Entrepreneurs in China’s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[wsê, ih, ompany, profile, john, porter, musé...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1086_517899</td>\n",
       "      <td>What Is Organizational Imprinting? Cultural En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[andrew_christensen, university_california, l...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1086_588742</td>\n",
       "      <td>Homeward Bound? Interest, Identity, and Invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[lawyers, consumer_protection, laws, stewart_...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1086_657524</td>\n",
       "      <td>Corporate Unity in American Trade Policy: A Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[establishing, sense, personal, control, tran...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1086_659639</td>\n",
       "      <td>The Credit Crisis as a Problem in the Sociolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[guess, who, coming, town, white_supremacy, e...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1525_irqr.2011.4.3.199</td>\n",
       "      <td>Science, Health, and Nationhood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  orgs_score  \\\n",
       "0  [[research, note, church_membership, netherlan...         1.0   \n",
       "1  [[polish, io_oo, sociological_review, issn, co...         1.0   \n",
       "2  [[article, jjdlbsj, grapliy, compassionate, eg...         1.0   \n",
       "3  [[reply, allison, more, comparing, regression_...         1.0   \n",
       "4  [[determinants, spousal, interaction, marital,...         1.0   \n",
       "5  [[wsê, ih, ompany, profile, john, porter, musé...         1.0   \n",
       "6  [[andrew_christensen, university_california, l...         1.0   \n",
       "7  [[lawyers, consumer_protection, laws, stewart_...         1.0   \n",
       "8  [[establishing, sense, personal, control, tran...         1.0   \n",
       "9  [[guess, who, coming, town, white_supremacy, e...         1.0   \n",
       "\n",
       "             edited_filename  \\\n",
       "0             10.1086_210179   \n",
       "1             10.1086_210317   \n",
       "2             10.1086_231084   \n",
       "3             10.1086_231174   \n",
       "4             10.1086_382347   \n",
       "5             10.1086_517899   \n",
       "6             10.1086_588742   \n",
       "7             10.1086_657524   \n",
       "8             10.1086_659639   \n",
       "9  10.1525_irqr.2011.4.3.199   \n",
       "\n",
       "                                        article_name  \n",
       "0   Where Do Interorganizational Networks Come From?  \n",
       "1  Civil Rights Law at Work: Sex Discrimination a...  \n",
       "2  Between Markets and Politics: Organizational R...  \n",
       "3                 World Society and the Nation‐State  \n",
       "4  Kinship Networks and Entrepreneurs in China’s ...  \n",
       "5  What Is Organizational Imprinting? Cultural En...  \n",
       "6  Homeward Bound? Interest, Identity, and Invest...  \n",
       "7  Corporate Unity in American Trade Policy: A Ne...  \n",
       "8  The Credit Crisis as a Problem in the Sociolog...  \n",
       "9                    Science, Health, and Nationhood  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cult_df = quickpickle_load(cult_labeled_fp)\n",
    "# relt_df = quickpickle_load(relt_labeled_fp)\n",
    "# demog_df = quickpickle_load(demog_labeled_fp)\n",
    "orgs_df = quickpickle_load(orgs_labeled_fp)\n",
    "\n",
    "orgs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orgs_score\n",
      "0.0    303\n",
      "0.5     10\n",
      "1.0    511\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check score distribution across classes\n",
    "# print(cult_df.groupby('cultural_score').size())\n",
    "# print()\n",
    "# print(relt_df.groupby('relational_score').size())\n",
    "# print()\n",
    "# print(demog_df.groupby('demographic_score').size())\n",
    "# print()\n",
    "print(orgs_df.groupby('orgs_score').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unsure cases: where X_score = 0.5\n",
    "drop_unsure = True\n",
    "\n",
    "if drop_unsure:\n",
    "#     cult_df_yes = cult_df[cult_df['cultural_score'] == 1.0]\n",
    "#     cult_df_no = cult_df[cult_df['cultural_score'] == 0.0]\n",
    "#     cult_df = pd.concat([cult_df_yes, cult_df_no])\n",
    "    \n",
    "#     relt_df_yes = relt_df[relt_df['relational_score'] == 1.0]\n",
    "#     relt_df_no = relt_df[relt_df['relational_score'] == 0.0]\n",
    "#     relt_df = pd.concat([relt_df_yes, relt_df_no])\n",
    "    \n",
    "#     demog_df_yes = demog_df[demog_df['demographic_score'] == 1.0]\n",
    "#     demog_df_no = demog_df[demog_df['demographic_score'] == 0.0]\n",
    "#     demog_df = pd.concat([demog_df_yes, demog_df_no])\n",
    "    \n",
    "    orgs_df_yes = orgs_df[orgs_df['orgs_score'] == 1.0]\n",
    "    orgs_df_no = orgs_df[orgs_df['orgs_score'] == 0.0]\n",
    "    orgs_df = pd.concat([orgs_df_yes, orgs_df_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Convert the data into token ids up to length max_len\n",
    "######################################################\n",
    "\n",
    "max_len = 500\n",
    "\n",
    "def obtain_token_ids(list_of_sentences, length = max_len):\n",
    "    \"\"\"\n",
    "    Obtains the preprocessed article and returns the token ids of the first `length` tokens.\n",
    "    Unknown words use a UNK_IDX token, sentence ends are represented with a \n",
    "    \n",
    "    Args:\n",
    "        list_of_sentences: a list of the tokenized sentences of words or phrases which constitute the article\n",
    "        length: the length to set the article\n",
    "    Returns:\n",
    "        A list of length `length` characterizing the input sentences\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = []\n",
    "    for sent in list_of_sentences:\n",
    "        for word in sent:\n",
    "            tokens.append(key2index[word] if word in key2index else UNK_IDX)\n",
    "        tokens.append(PERIOD_IDX)\n",
    "        if len(tokens) >= length:\n",
    "            break\n",
    "    if len(tokens) < length:\n",
    "        tokens += [PAD_IDX] * (length - len(tokens))\n",
    "    return tokens[:length]\n",
    "\n",
    "\n",
    "def transform_dataframe(df):\n",
    "    return np.stack(df.text.apply(obtain_token_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data size: train (732, 500) test (82, 500)\n",
      "new data size: train (926, 500) test (96, 500)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_cult = transform_dataframe(orgs_df)\n",
    "Y = orgs_df['orgs_score'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cult, Y, test_size=0.10, random_state=42)\n",
    "print('original data size: train', X_train.shape, 'test', X_test.shape)\n",
    "\n",
    "def oversample_shuffle(X, y):\n",
    "    ros = RandomOverSampler(random_state=42, sampling_strategy=1.0)\n",
    "    X, y = ros.fit_resample(X, y)\n",
    "    p = np.random.permutation(len(X))\n",
    "    return X[p], y[p]\n",
    "\n",
    "X_train, y_train = oversample_shuffle(X_train, y_train)\n",
    "X_test, y_test = oversample_shuffle(X_test, y_test)\n",
    "print('new data size: train', X_train.shape, 'test', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=12):\n",
    "    batches_x=[]\n",
    "    batches_y=[]\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        batches_x.append(torch.LongTensor(x[i:i+batch_size]))\n",
    "        batches_y.append(torch.FloatTensor(y[i:i+batch_size]))\n",
    "    return batches_x, batches_y\n",
    "\n",
    "\n",
    "batch_X_train, batch_y_train = get_batches(X_train, y_train)\n",
    "batch_X_test, batch_y_test = get_batches(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Prepares a CNN model that will take in a list of token ids and output a predicted probability\n",
    "######################################################\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq_len = max_len\n",
    "              \n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            torch.cat([torch.FloatTensor(w2v_model.wv.vectors), \n",
    "               torch.zeros((1, embedding_dim), dtype=torch.float), \n",
    "               torch.randn((2, embedding_dim), dtype=torch.float)], \n",
    "              dim=0), \n",
    "            freeze=False)\n",
    "\n",
    "        self.conv_1 = nn.Conv1d(in_channels=300, out_channels=50, kernel_size=1, stride=1)\n",
    "        self.pool_1 = nn.MaxPool1d(kernel_size=self.seq_len, stride=1)\n",
    "\n",
    "        self.conv_2 = nn.Conv1d(in_channels=300, out_channels=50, kernel_size=2, stride=1)\n",
    "        self.pool_2 = nn.MaxPool1d(kernel_size=self.seq_len-1, stride=1)\n",
    "\n",
    "        self.conv_3 = nn.Conv1d(in_channels=300, out_channels=50, kernel_size=3, stride=1)\n",
    "        self.pool_3 = nn.MaxPool1d(kernel_size=self.seq_len-2, stride=1)\n",
    "\n",
    "        self.fc = nn.Linear(50 * 3, 1)\n",
    "\n",
    "    \n",
    "    def forward(self, x): \n",
    "        x0 = self.embeddings(x)\n",
    "        \n",
    "        x0 = x0.permute(0, 2, 1)\n",
    "\n",
    "        x1 = torch.tanh(self.conv_1(x0))\n",
    "        x1 = self.pool_1(x1)\n",
    "\n",
    "        x2 = torch.tanh(self.conv_2(x0))\n",
    "        x2 = self.pool_2(x2)\n",
    "\n",
    "        x3 = torch.tanh(self.conv_3(x0))\n",
    "        x3 = self.pool_3(x3)\n",
    "\n",
    "        combined=torch.cat((x1, x2, x3), axis=1).squeeze()\n",
    "        \n",
    "        out = self.fc(combined)\n",
    "        return F.sigmoid(out.squeeze())\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.eval()\n",
    "        y = []\n",
    "        with torch.no_grad():\n",
    "            for x in X:\n",
    "                y_preds = self.forward(x)\n",
    "                y.append(y_preds)\n",
    "        return torch.cat(y, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, num_epochs=8):\n",
    "    \"\"\"\n",
    "    Runs a training loop for a given pytorch model, optimizer, and loss function for num_epochs epochs\n",
    "    \"\"\"\n",
    "\n",
    "    best_dev_acc = 0.\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "        for x, y in zip(batch_X_train, batch_y_train):\n",
    "            y_pred = model.forward(x)\n",
    "            loss = loss_fn(y_pred.view(-1), y.view(-1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        predictions = model.predict(batch_X_test).cpu().numpy()\n",
    "\n",
    "        dev_accuracy = accuracy_score(y_test, predictions > 0.5)\n",
    "        best_dev_acc = max(best_dev_acc, dev_accuracy)\n",
    "        dev_roc = roc_auc_score(y_test, predictions)\n",
    "        if epoch % 1 == 0:\n",
    "            print(\"Epoch %s, dev accuracy: %.3f, dev AUC: %.3f\" % (epoch, dev_accuracy, dev_roc))\n",
    "\n",
    "    print(\"\\nBest Performing Model achieves dev accuracy of : %.3f\" % (best_dev_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, dev accuracy: 0.646, dev AUC: 0.691\n",
      "Epoch 1, dev accuracy: 0.740, dev AUC: 0.779\n",
      "Epoch 2, dev accuracy: 0.802, dev AUC: 0.805\n",
      "Epoch 3, dev accuracy: 0.802, dev AUC: 0.807\n",
      "Epoch 4, dev accuracy: 0.802, dev AUC: 0.809\n",
      "Epoch 5, dev accuracy: 0.802, dev AUC: 0.809\n",
      "Epoch 6, dev accuracy: 0.802, dev AUC: 0.806\n",
      "Epoch 7, dev accuracy: 0.802, dev AUC: 0.805\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.802\n"
     ]
    }
   ],
   "source": [
    "# For reproducible results, sets a random seed and trains the CNN model\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "train(model, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Prepares an LSTM model that will take in a list of token ids and output a predicted probability\n",
    "######################################################\n",
    "\n",
    "class LSTM(torch.nn.Module) :\n",
    "    def __init__(self, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            torch.cat([torch.FloatTensor(w2v_model.wv.vectors), \n",
    "               torch.zeros((1, embedding_dim), dtype=torch.float), \n",
    "               torch.randn((2, embedding_dim), dtype=torch.float)], \n",
    "              dim=0), \n",
    "            freeze=False)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (h, c) = self.lstm(x)\n",
    "        return F.sigmoid(self.linear(h[-1]))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.eval()\n",
    "        y = []\n",
    "        with torch.no_grad():\n",
    "            for x in X:\n",
    "                y_preds = self.forward(x)\n",
    "                y.append(y_preds)\n",
    "        return torch.cat(y, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, dev accuracy: 0.573, dev AUC: 0.621\n",
      "Epoch 1, dev accuracy: 0.781, dev AUC: 0.762\n",
      "Epoch 2, dev accuracy: 0.729, dev AUC: 0.785\n",
      "Epoch 3, dev accuracy: 0.646, dev AUC: 0.766\n",
      "Epoch 4, dev accuracy: 0.698, dev AUC: 0.784\n",
      "Epoch 5, dev accuracy: 0.677, dev AUC: 0.788\n",
      "Epoch 6, dev accuracy: 0.677, dev AUC: 0.785\n",
      "Epoch 7, dev accuracy: 0.677, dev AUC: 0.790\n",
      "\n",
      "Best Performing Model achieves dev accuracy of : 0.781\n"
     ]
    }
   ],
   "source": [
    "# For reproducible results, sets a random seed and trains the LSTM model\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = LSTM(300)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "train(model, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
