{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare classification methods for identifying org. science perspectives in JSTOR articles\n",
    "## Using balanced samples from hand-labeled set of articles\n",
    "\n",
    "@author: Jaren Haber, PhD<br>\n",
    "@coauthors: Prof. Heather Haveman, UC Berkeley; Yoon Sung Hong, Wayfair<br>\n",
    "@contact: Jaren.Haber@georgetown.edu<br>\n",
    "@project: Computational Literature Review of Organizational Scholarship<br>\n",
    "@date: December 2020\n",
    "\n",
    "'''\n",
    "Trains classifiers to predict whether an article is about a given perspective in org. science. To train the classifiers, uses preliminary labeled articles, broken down as follows: \n",
    "Cultural: 105 yes, 209 no\n",
    "Relational: 92 yes, 230 no\n",
    "Demographic: 77 yes, 249 no\n",
    "Compares f1_weighted scores of four model structures using 10-Fold Cross Validation: Logistic regression, SVM, Naive Bayes, and Decision Tree. Oversamples training data to .7 (7:10 minority:majority class).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 6.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (7.0)\n",
      "Collecting joblib (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/5b/bd0f0fb5564183884d8e35b81d06d7ec06a20d1a0c8b4c407f1554691dce/joblib-1.0.0-py3-none-any.whl (302kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 21.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/28/ff0d0936a31f15a0879caf6dac1f1cbaab1fc7b9e8baf8a1d5a70380fb22/regex-2020.11.13-cp37-cp37m-manylinux2010_x86_64.whl (667kB)\n",
      "\u001b[K     |████████████████████████████████| 675kB 20.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/02/8f8880a4fd6625461833abcf679d4c12a44c76f9925f92bf212bb6cefaad/tqdm-4.56.0-py2.py3-none-any.whl (72kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 39.7MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "Successfully built nltk\n",
      "Installing collected packages: joblib, regex, tqdm, nltk\n",
      "Successfully installed joblib-1.0.0 nltk-3.5 regex-2020.11.13 tqdm-4.56.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Import libraries\n",
    "######################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import csv\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, KFold\n",
    "\n",
    "# !pip install imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import sys; sys.path.insert(0, \"../preprocess/\") # For loading functions from files in other directory\n",
    "from quickpickle import quickpickle_dump, quickpickle_load # custom scripts for quick saving & loading to pickle format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Define filepaths\n",
    "######################################################\n",
    "\n",
    "thisday = date.today().strftime(\"%m%d%y\")\n",
    "\n",
    "cwd = os.getcwd()\n",
    "root = str.replace(cwd, 'classification/modeling', '')\n",
    "\n",
    "# Directory for prepared data and trained models: save files here\n",
    "data_fp = root + 'classification/data/'\n",
    "model_fp = root + 'classification/models/'\n",
    "\n",
    "# Current article lists\n",
    "article_list_fp = data_fp + 'filtered_length_index.csv' # Filtered index of research articles\n",
    "article_paths_fp = data_fp + 'filtered_length_article_paths.csv' # List of article file paths\n",
    "\n",
    "# Preprocessed training data\n",
    "cult_labeled_fp = data_fp + 'training_cultural_preprocessed_121620.pkl'\n",
    "relt_labeled_fp = data_fp + 'training_relational_preprocessed_121620.pkl'\n",
    "demog_labeled_fp = data_fp + 'training_demographic_preprocessed_121620.pkl'\n",
    "\n",
    "# Model filepaths\n",
    "cult_model_fp = model_fp + f'classifier_cult_MLP_{str(thisday)}.joblib'\n",
    "relt_model_fp = model_fp + f'classifier_relt_MLP_{str(thisday)}.joblib'\n",
    "demog_model_fp = model_fp + f'classifier_demog_MLP_{str(thisday)}.joblib'\n",
    "\n",
    "# Vectorizers trained on hand-coded data (use to limit vocab of input texts)\n",
    "cult_vec_fp = model_fp + 'vectorizer_cult_121620.joblib'\n",
    "relt_vec_fp = model_fp + 'vectorizer_relt_121620.joblib'\n",
    "demog_vec_fp = model_fp + 'vectorizer_demog_121620.joblib'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cultural_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[journal, of, managerial, issues, vol, xxiii,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[organization, ht, icna, vol, no, may, june, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[from, fiefs, to, clans, and, network, capita...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[the, collective, strategy, framework, an, ap...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[manag, int, rev, doi, sl, research, article,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[int, studies, ofmgt, amp, org, vol, no, pp, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[linking, organizational, values, to, relatio...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[journal, of, organizational, behavior, organ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[®, academy, oí, management, learning, amp, e...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[strategie, management, journal, strat, mgmt,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cultural_score\n",
       "0  [[journal, of, managerial, issues, vol, xxiii,...             1.0\n",
       "1  [[organization, ht, icna, vol, no, may, june, ...             1.0\n",
       "2  [[from, fiefs, to, clans, and, network, capita...             1.0\n",
       "3  [[the, collective, strategy, framework, an, ap...             1.0\n",
       "4  [[manag, int, rev, doi, sl, research, article,...             1.0\n",
       "5  [[int, studies, ofmgt, amp, org, vol, no, pp, ...             1.0\n",
       "6  [[linking, organizational, values, to, relatio...             1.0\n",
       "7  [[journal, of, organizational, behavior, organ...             1.0\n",
       "8  [[®, academy, oí, management, learning, amp, e...             1.0\n",
       "9  [[strategie, management, journal, strat, mgmt,...             1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cult_df = quickpickle_load(cult_labeled_fp)\n",
    "relt_df = quickpickle_load(relt_labeled_fp)\n",
    "demog_df = quickpickle_load(demog_labeled_fp)\n",
    "\n",
    "cult_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cultural_score\n",
      "0.0    209\n",
      "0.5     12\n",
      "1.0    133\n",
      "dtype: int64\n",
      "\n",
      "relational_score\n",
      "0.0    229\n",
      "0.5      7\n",
      "1.0    114\n",
      "dtype: int64\n",
      "\n",
      "demographic_score\n",
      "0.0    248\n",
      "0.5      5\n",
      "1.0    101\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check score distribution across classes\n",
    "print(cult_df.groupby('cultural_score').size())\n",
    "print()\n",
    "print(relt_df.groupby('relational_score').size())\n",
    "print()\n",
    "print(demog_df.groupby('demographic_score').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unsure cases: where X_score = 0.5\n",
    "drop_unsure = True\n",
    "\n",
    "if drop_unsure:\n",
    "    cult_df_yes = cult_df[cult_df['cultural_score'] == 1.0]\n",
    "    cult_df_no = cult_df[cult_df['cultural_score'] == 0.0]\n",
    "    cult_df = pd.concat([cult_df_yes, cult_df_no])\n",
    "    \n",
    "    relt_df_yes = relt_df[relt_df['relational_score'] == 1.0]\n",
    "    relt_df_no = relt_df[relt_df['relational_score'] == 0.0]\n",
    "    relt_df = pd.concat([relt_df_yes, relt_df_no])\n",
    "    \n",
    "    demog_df_yes = demog_df[demog_df['demographic_score'] == 1.0]\n",
    "    demog_df_no = demog_df[demog_df['demographic_score'] == 0.0]\n",
    "    demog_df = pd.concat([demog_df_yes, demog_df_no])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check vocab size and frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def collect_article_tokens(article, return_string=False):\n",
    "    '''\n",
    "    Collects words from already-tokenized sentences representing each article.\n",
    "    \n",
    "    Args:\n",
    "        article: list of lists of words (each list is a sentence)\n",
    "        return_string: whether to return single, long string representing article\n",
    "    Returns:\n",
    "        tokens: string if return_string, else list of tokens\n",
    "    '''\n",
    "    \n",
    "    tokens = [] # initialize\n",
    "    \n",
    "    if return_string:\n",
    "        for sent in article:\n",
    "            sent = ' '.join(sent) # make sentence into a string\n",
    "            tokens.append(sent) # add sentence to list of sentences\n",
    "        tokens = ' '.join(tokens) # join sentences into string\n",
    "        return tokens # return string\n",
    "    \n",
    "    else:\n",
    "        for sent in article:\n",
    "            tokens += [word for word in sent] # add each word to list of tokens\n",
    "        return tokens # return list of tokens\n",
    "\n",
    "# For capturing word frequencies, add all words from each article to single, shared list (can't use this to create models)\n",
    "cult_tokens = []; cult_df['text'].apply(lambda article: cult_tokens.extend([word for word in collect_article_tokens(article)]))\n",
    "relt_tokens = []; relt_df['text'].apply(lambda article: relt_tokens.extend([word for word in collect_article_tokens(article)]))\n",
    "demog_tokens = []; demog_df['text'].apply(lambda article: demog_tokens.extend([word for word in collect_article_tokens(article)]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 80217\n",
      "\n",
      "20 most frequent words in labeled articles:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 596822),\n",
       " ('of', 428762),\n",
       " ('and', 330459),\n",
       " ('in', 232360),\n",
       " ('to', 218627),\n",
       " ('that', 117768),\n",
       " ('is', 103616),\n",
       " ('for', 94102),\n",
       " ('as', 76669),\n",
       " ('on', 63680),\n",
       " ('are', 63279),\n",
       " ('with', 59141),\n",
       " ('by', 57364),\n",
       " ('this', 53800),\n",
       " ('be', 47394),\n",
       " ('oasis', 46263),\n",
       " ('or', 42620),\n",
       " ('it', 40088),\n",
       " ('entry', 39972),\n",
       " ('from', 39891)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at size of vocabulary and most frequent words\n",
    "tokens = (cult_tokens + relt_tokens) + demog_tokens\n",
    "print('Vocab size:', len(set(tokens)))\n",
    "print()\n",
    "\n",
    "# Check out most frequent words in labeled texts\n",
    "freq = Counter(tokens)\n",
    "print('20 most frequent words in labeled articles:')\n",
    "freq.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check frequent sentences (to improve cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 133028\n",
      "\n",
      "20 most frequent sentences in labeled articles:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('colsep', 12325),\n",
       " ('rowsep', 12319),\n",
       " ('oasis entry colname', 11914),\n",
       " ('char', 7881),\n",
       " ('align char', 7802),\n",
       " ('valign bottom oasis entry', 7243),\n",
       " ('oasis row', 6022),\n",
       " ('align center', 2775),\n",
       " ('valign bottom', 2595),\n",
       " ('oasis entry colname colsep rowsep align char char oasis entry', 1589),\n",
       " ('align left', 1573),\n",
       " ('oasis entry colname colsep rowsep align char char', 1250),\n",
       " ('oasis entry colsep rowsep valign bottom oasis entry', 1045),\n",
       " ('label label', 767),\n",
       " ('fn', 744),\n",
       " ('sec', 606),\n",
       " ('oasis colspec colnum colname colwidth pi', 573),\n",
       " ('sec id sc', 560),\n",
       " ('oasis entry colsep rowsep oasis entry', 531),\n",
       " ('fn id fn', 509)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add sentences from each article to empty list:\n",
    "cult_sents = []; cult_df['text'].apply(\n",
    "    lambda article: cult_sents.extend(\n",
    "        [' '.join([word for word in sent]) for sent in article]))\n",
    "relt_sents = []; relt_df['text'].apply(\n",
    "    lambda article: relt_sents.extend(\n",
    "        [' '.join([word for word in sent]) for sent in article]))\n",
    "demog_sents = []; demog_df['text'].apply(\n",
    "    lambda article: demog_sents.extend(\n",
    "        [' '.join([word for word in sent]) for sent in article]))\n",
    "\n",
    "sents = (cult_sents + relt_sents) + demog_sents\n",
    "print('Number of sentences:', len(sents))\n",
    "print()\n",
    "\n",
    "# Check out most frequent sentences in labeled texts\n",
    "freq = Counter(sents)\n",
    "print('20 most frequent sentences in labeled articles:')\n",
    "freq.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and apply text vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect articles: Add each article as single str to list of str:\n",
    "cult_docs = [] # empty list\n",
    "cult_df['text'].apply(\n",
    "    lambda article: cult_docs.append(\n",
    "        collect_article_tokens(\n",
    "            article, \n",
    "            return_string=True)))\n",
    "\n",
    "relt_docs = [] # empty list\n",
    "relt_df['text'].apply(\n",
    "    lambda article: relt_docs.append(\n",
    "       collect_article_tokens(\n",
    "            article, \n",
    "            return_string=True)))\n",
    "\n",
    "demog_docs = [] # empty list\n",
    "demog_df['text'].apply(\n",
    "    lambda article: demog_docs.append(\n",
    "        collect_article_tokens(\n",
    "            article, \n",
    "            return_string=True)))\n",
    "\n",
    "print() # skip weird output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in cultural vectorizer: 66098\n",
      "['aa', 'affects', 'analogize', 'argumentatively', 'aveni', 'beifuss', 'blustein', 'buchholtz', 'carron', 'childlessness', 'coinciding', 'confused', 'councillors', 'czabansku', 'demirguc', 'dijeffren', 'dogs', 'economets', 'endler', 'ethnidzed', 'fad', 'fiskarbankadministrasjon', 'frenzen', 'ger', 'greenwood', 'haskell', 'hobson', 'identified', 'indexes', 'interceded', 'itbs', 'kaleidoscope', 'kraiger', 'legalized', 'lockett', 'makrosoziologie', 'mcenough', 'millenarian', 'mot', 'ncjrs', 'noninstrumental', 'offaculty', 'oshpd', 'parsimonious', 'phase', 'poovanalingum', 'primatively', 'punctuate', 'readership', 'relabeled', 'review', 'ruddy', 'schneider', 'severed', 'site', 'sparrowe', 'stochas', 'superlative', 'taurus', 'thus', 'transitioning', 'ularco', 'unsafe', 'vessies', 'weekends', 'wrinkle', 'ïï']\n",
      "\n",
      "Number of features in relational vectorizer: 64919\n",
      "['aa', 'affordance', 'ancestors', 'arose', 'aydin', 'benefitted', 'bonacich', 'burkart', 'ccc', 'circumventing', 'commodcomposition', 'contempowith', 'criticised', 'decadence', 'destroys', 'dispassionate', 'dube', 'eloy', 'ereignet', 'explosivefrom', 'fight', 'fracture', 'generalised', 'grants', 'harmoniic', 'hoard', 'identit', 'indices', 'interdis', 'iunmar', 'kangaroo', 'krise', 'lementair', 'longitudinal', 'malmo', 'meandeviated', 'minutes', 'mrvar', 'neighbor', 'nonshacho', 'oijt', 'opportunists', 'paedophiles', 'perfonnance', 'plundering', 'prejudiced', 'prowse', 'raphy', 'regular', 'retaining', 'rounded', 'schaechter', 'series', 'singleproject', 'sozialen', 'stipends', 'superconducting', 'taxing', 'tiefigrom', 'transzendentale', 'unanticipate', 'unwind', 'violently', 'wheatsheaf', 'xtxwit']\n",
      "\n",
      "Number of features in demographic vectorizer: 63542\n",
      "['aa', 'aforementioned', 'ancilliary', 'aronsson', 'aydin', 'benevolence', 'bond', 'burkhalter', 'ccnrwtcidi', 'citationsa', 'communalities', 'contextual', 'cronache', 'decisionistic', 'deterministic', 'disquieting', 'dumb', 'embarrassed', 'erupts', 'extra', 'finesse', 'frederica', 'geographies', 'greyser', 'hays', 'homelike', 'ija', 'inequities', 'interrupted', 'jason', 'kekre', 'lackey', 'libertarians', 'lrus', 'mario', 'mentd', 'mockery', 'mutualism', 'nificance', 'nummarr', 'operandi', 'oç', 'perchoices', 'plunged', 'premed', 'prussia', 'rated', 'reinhart', 'revenues', 'ruckgr', 'schuette', 'shaking', 'skogan', 'spiritedness', 'strik', 'swamp', 'tenor', 'tjto', 'truisms', 'undesirable', 'vague', 'wahrman', 'withdrawn', 'zat']\n"
     ]
    }
   ],
   "source": [
    "# Define stopwords used by JSTOR\n",
    "jstor_stopwords = set([\"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\", \"for\", \"if\", \"in\", \"into\", \"is\", \"it\", \"no\", \"not\", \"of\", \"on\", \"or\", \"such\", \"that\", \"the\", \"their\", \"then\", \"there\", \"these\", \"they\", \"this\", \"to\", \"was\", \"will\", \"with\"])\n",
    "\n",
    "# Uses TFIDF weighted DTM because results in better classifier accuracy than unweighted\n",
    "cult_vectorizer = joblib.load(cult_vec_fp, \"r+\")\n",
    "X_cult = cult_vectorizer.transform(cult_docs)\n",
    "print('Number of features in cultural vectorizer:', len(cult_vectorizer.get_feature_names()))\n",
    "print(cult_vectorizer.get_feature_names()[::1000]) # get every 1000th word\n",
    "print()\n",
    "\n",
    "relt_vectorizer = joblib.load(relt_vec_fp, \"r+\")\n",
    "X_relt = relt_vectorizer.transform(relt_docs)\n",
    "print('Number of features in relational vectorizer:', len(relt_vectorizer.get_feature_names()))\n",
    "print(relt_vectorizer.get_feature_names()[::1000]) # get every 1000th word\n",
    "print()\n",
    "\n",
    "demog_vectorizer = joblib.load(demog_vec_fp, \"r+\")\n",
    "X_demog = demog_vectorizer.transform(demog_docs)\n",
    "print('Number of features in demographic vectorizer:', len(demog_vectorizer.get_feature_names()))\n",
    "print(demog_vectorizer.get_feature_names()[::1000]) # get every 1000th word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Balance x_train, y_train\n",
    "######################################################\n",
    "\n",
    "def resample_data(X_train, Y_train, undersample = False, sampling_ratio = 1.0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_train: X training data\n",
    "        Y_train: Y training data\n",
    "        undersample: boolean for over or undersampling\n",
    "        sampling_ratio: ratio of minority to majority class\n",
    "        \n",
    "        archived/not used:\n",
    "        sampling_strategy: strategy for resampled distribution\n",
    "            if oversample: 'majority' makes minority = to majority\n",
    "            if undersample: 'minority' makes majority = to minority\n",
    "            \n",
    "    Returns:\n",
    "        X_balanced: predictors at balanced ratio\n",
    "        Y_balanced: outcomes at balanced ratio\n",
    "    \"\"\"\n",
    "    \n",
    "    if undersample == True:\n",
    "        undersample = RandomUnderSampler(sampling_strategy=sampling_ratio)\n",
    "        X_balanced, Y_balanced = undersample.fit_resample(X_train, Y_train)\n",
    "    else:\n",
    "        oversample = RandomOverSampler(sampling_strategy=sampling_ratio)\n",
    "        X_balanced, Y_balanced = oversample.fit_resample(X_train, Y_train)\n",
    "    \n",
    "    print(f'Y_train: {Counter(Y_train)}\\nY_resample: {Counter(Y_balanced)}')\n",
    "    \n",
    "    return X_balanced, Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# k-fold cross validation for model evaluation\n",
    "######################################################\n",
    "\n",
    "# Define test options for k-fold CV\n",
    "num_folds = 10 \n",
    "seed = 3\n",
    "scoring='f1_weighted' # set scoring metric (not used here)\n",
    "\n",
    "def show_kfold_output(models, \n",
    "                      X, \n",
    "                      Y, \n",
    "                      num_folds = num_folds, \n",
    "                      random_state = seed, \n",
    "                      shuffle = True):\n",
    "    '''\n",
    "    Estimates the accuracy of different model algorithms, adds results to a results array and returns.\n",
    "    Prints the accuracy results: averages and std.\n",
    "    Uses cross_val_predict, which unlike cross_val_score cannot define scoring option/evaluation metric.\n",
    "    \n",
    "    Args:\n",
    "        models: list of (name, model) tuples\n",
    "        X: predictors\n",
    "        Y: outcomes\n",
    "        num_folds: Split data randomly into num_folds parts: (num_folds-1) for training, 1 for scoring\n",
    "        random_state: seed\n",
    "        shuffle: \n",
    "    \n",
    "    Returns:\n",
    "        results: list of model results\n",
    "        names: list of model names (matches results)\n",
    "        \n",
    "    Source: \n",
    "        https://stackoverflow.com/questions/40057049/using-confusion-matrix-as-scoring-metric-in-cross-validation-in-scikit-learn\n",
    "    '''\n",
    "    \n",
    "    results = []\n",
    "    names = []\n",
    "    \n",
    "    for name, model in models:\n",
    "        # Setup model options\n",
    "        kfold = KFold(\n",
    "            n_splits=num_folds, \n",
    "            random_state=seed, \n",
    "            shuffle=True)\n",
    "        \n",
    "        # Get kfold results\n",
    "        cv_results = cross_val_predict(\n",
    "            model, \n",
    "            X, \n",
    "            Y, \n",
    "            cv=kfold, \n",
    "            #scoring=scoring, \n",
    "            n_jobs=-1) # use all cores = faster\n",
    "        \n",
    "        # Add results and name of each algorithm to the model array\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        \n",
    "        # Print results\n",
    "        print(f'{name}:')\n",
    "        print()\n",
    "        print(f'Mean (std):\\t {round(cv_results.mean(),4)} ({round(cv_results.std(),4)})')\n",
    "        print(f'Accuracy:\\t', {round(accuracy_score(Y_balanced, cv_results)), 4})\n",
    "        print()\n",
    "        print('Confusion matrix:\\n', confusion_matrix(Y_balanced, cv_results))\n",
    "        print()\n",
    "        print('Report:\\n', classification_report(Y_balanced, cv_results))\n",
    "        print()\n",
    "        \n",
    "    # Return arrays\n",
    "    return results, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate algorithms: Cultural perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 342\n",
      "Number of codes (should match): 342\n",
      "Y_train Distribution: [(0.0, 165), (1.0, 108)]\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Prepare training and validation data\n",
    "######################################################\n",
    "\n",
    "# Separate training and final validation data set. First remove class\n",
    "# label from data (X). Setup target class (Y)\n",
    "# Then make the validation set 10% of the entire\n",
    "# set of labeled data (X_validate, Y_validate)\n",
    "\n",
    "cult_df = cult_df[['text', 'cultural_score']]\n",
    "print(\"Number of cases:\", str(X_cult.shape[0]))\n",
    "\n",
    "valueArray = cult_df.values\n",
    "Y = valueArray[:,1]\n",
    "Y = Y.astype('float')\n",
    "print(\"Number of codes (should match):\", str(len(Y)))\n",
    "\n",
    "test_size = 0.2\n",
    "seed = 3\n",
    "X_train, X_validate, Y_train, Y_validate = train_test_split(\n",
    "    X_cult, \n",
    "    Y, \n",
    "    test_size=test_size, \n",
    "    random_state=seed)\n",
    "\n",
    "print(f'Y_train Distribution: {Counter(Y_train).most_common()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train: Counter({0.0: 209, 1.0: 133})\n",
      "Y_resample: Counter({1.0: 209, 0.0: 209})\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Oversample to desirable ratio\n",
    "######################################################\n",
    "\n",
    "# Use these settings here and below\n",
    "sampling_ratio = 1.0 # ratio of minority to majority cases\n",
    "undersample = False # whether to undersample or oversample\n",
    "\n",
    "X_balanced, Y_balanced = resample_data(\n",
    "    X_cult, \n",
    "    Y, \n",
    "    undersample=undersample, \n",
    "    sampling_ratio=sampling_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors (KNN):\n",
      "\n",
      "Mean (std):\t 0.6172 (0.4861)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[140  69]\n",
      " [ 20 189]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.67      0.76       209\n",
      "         1.0       0.73      0.90      0.81       209\n",
      "\n",
      "    accuracy                           0.79       418\n",
      "   macro avg       0.80      0.79      0.78       418\n",
      "weighted avg       0.80      0.79      0.78       418\n",
      "\n",
      "\n",
      "Random Forest (RF):\n",
      "\n",
      "Mean (std):\t 0.4904 (0.4999)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[191  18]\n",
      " [ 22 187]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.91      0.91       209\n",
      "         1.0       0.91      0.89      0.90       209\n",
      "\n",
      "    accuracy                           0.90       418\n",
      "   macro avg       0.90      0.90      0.90       418\n",
      "weighted avg       0.90      0.90      0.90       418\n",
      "\n",
      "\n",
      "Decision Tree (DT):\n",
      "\n",
      "Mean (std):\t 0.5526 (0.4972)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[159  50]\n",
      " [ 28 181]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.76      0.80       209\n",
      "         1.0       0.78      0.87      0.82       209\n",
      "\n",
      "    accuracy                           0.81       418\n",
      "   macro avg       0.82      0.81      0.81       418\n",
      "weighted avg       0.82      0.81      0.81       418\n",
      "\n",
      "\n",
      "Multinomial Naive Bayes (MNB):\n",
      "\n",
      "Mean (std):\t 0.8397 (0.3669)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 67 142]\n",
      " [  0 209]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.32      0.49       209\n",
      "         1.0       0.60      1.00      0.75       209\n",
      "\n",
      "    accuracy                           0.66       418\n",
      "   macro avg       0.80      0.66      0.62       418\n",
      "weighted avg       0.80      0.66      0.62       418\n",
      "\n",
      "\n",
      "Logistic Regression (LR):\n",
      "\n",
      "Mean (std):\t 0.4761 (0.4994)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[190  19]\n",
      " [ 29 180]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.91      0.89       209\n",
      "         1.0       0.90      0.86      0.88       209\n",
      "\n",
      "    accuracy                           0.89       418\n",
      "   macro avg       0.89      0.89      0.89       418\n",
      "weighted avg       0.89      0.89      0.89       418\n",
      "\n",
      "\n",
      "Support Vector Machine (SVM):\n",
      "\n",
      "Mean (std):\t 0.5215 (0.4995)\n",
      "Accuracy:\t {0, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 91 118]\n",
      " [109 100]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.44      0.44       209\n",
      "         1.0       0.46      0.48      0.47       209\n",
      "\n",
      "    accuracy                           0.46       418\n",
      "   macro avg       0.46      0.46      0.46       418\n",
      "weighted avg       0.46      0.46      0.46       418\n",
      "\n",
      "\n",
      "Multi-Layer Perceptron (MLP):\n",
      "\n",
      "Mean (std):\t 0.5072 (0.4999)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[187  22]\n",
      " [ 19 190]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.89      0.90       209\n",
      "         1.0       0.90      0.91      0.90       209\n",
      "\n",
      "    accuracy                           0.90       418\n",
      "   macro avg       0.90      0.90      0.90       418\n",
      "weighted avg       0.90      0.90      0.90       418\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Use different algorithms to build models\n",
    "######################################################\n",
    "\n",
    "models = []\n",
    "models.append(('K-Nearest Neighbors (KNN)', KNeighborsClassifier()))\n",
    "models.append(('Random Forest (RF)', RandomForestClassifier(random_state=seed)))\n",
    "models.append(('Decision Tree (DT)', DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('Multinomial Naive Bayes (MNB)', MultinomialNB()))\n",
    "models.append(('Logistic Regression (LR)', LogisticRegression(random_state=seed)))\n",
    "models.append(('Support Vector Machine (SVM)', SVC(gamma='auto')))\n",
    "models.append(('Multi-Layer Perceptron (MLP)', MLPClassifier(max_iter=100, activation='relu')))\n",
    "\n",
    "# Evaluate algorithms using 10-fold cross validation\n",
    "results, names = show_kfold_output(models=models, \n",
    "                                   X=X_balanced, \n",
    "                                   Y=Y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/work/classification/models/classifier_cult_MLP_012221.joblib']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################\n",
    "# Save best model\n",
    "######################################################\n",
    "\n",
    "cult_model = MLPClassifier(max_iter=100, activation='relu').fit(X_balanced, Y_balanced) # DecisionTreeClassifier(random_state=seed).fit(X_relt, Y) # RandomForestClassifier(random_state=seed).fit(X_balanced, Y_balanced)\n",
    "joblib.dump(cult_model, cult_model_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation step: Use selected model to predict class probabilities in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions(text, vectorizer_model, class_model):\n",
    "    '''\n",
    "    Predicts the label for an input article using a given model trained to classify organizational perspectives in articles. \n",
    "    Uses vectorizer_model to restrict the vocab of the input article so it's consistent with vocab in class_model (avoids errors).\n",
    "    \n",
    "    Args:\n",
    "        text: preprocessed article text in format of list of sentences, each a str or list of tokens\n",
    "        vectorizer_model: fitted text vectorizer\n",
    "        class_model: trained classification model\n",
    "    Returns:\n",
    "        label: label for text predicted by model, false for tie\n",
    "        prob: probability for label\n",
    "    '''\n",
    "    \n",
    "    X = vectorizer_model.transform(text) # create TF-IDF-weighted DTM from text\n",
    "    probabilities = class_model.predict_proba(X)\n",
    "    \n",
    "    label = 'no'\n",
    "    prob_no = probabilities[0][0]\n",
    "    prob_yes = probabilities[0][1]\n",
    "    \n",
    "    # predicted label is one with greater probability\n",
    "    if probabilities[0][0] < probabilities[0][1]:\n",
    "        label = 'yes'\n",
    "        \n",
    "    return label, prob_yes, prob_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "Predicting: cultural persp.: 100%|██████████| 342/342 [00:25<00:00, 13.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "cult_model = MLPClassifier(max_iter=100, activation='relu').fit(X_cult, Y) # DecisionTreeClassifier(random_state=seed).fit(X_relt, Y)\n",
    "tqdm.pandas(desc = \"Predicting: cultural persp.\")\n",
    "cult_df[['prediction_cult','prediction_cult_prob_yes','prediction_cult_prob_no']] = cult_df['text'].progress_apply(lambda sentlist: pd.Series(compute_predictions([' '.join(sent) for sent in sentlist], cult_vectorizer, cult_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     208\n",
       "yes    134\n",
       "Name: prediction_cult, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out predictions: labels should be balanced\n",
    "pred_col = 'prediction_cult'\n",
    "cult_df[pred_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of labeled cultural data: [(0.0, 209), (1.0, 133)]\n"
     ]
    }
   ],
   "source": [
    "# Compare to distribution of labeled data\n",
    "print(f'Distribution of labeled cultural data: {Counter(Y).most_common()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc4d7e58048>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check out predicted probabilities: Distribution should be balanced\n",
    "prob_col = 'prediction_cult_prob_yes'\n",
    "cult_df[prob_col].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate algorithms: Relational perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 343\n",
      "Number of codes (should match): 343\n",
      "Y_train Distribution: [(0.0, 183), (1.0, 91)]\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Prepare training and validation data\n",
    "######################################################\n",
    "\n",
    "# Separate training and final validation data set. First remove class\n",
    "# label from data (X). Setup target class (Y)\n",
    "# Then make the validation set 10% of the entire\n",
    "# set of labeled data (X_validate, Y_validate)\n",
    "\n",
    "relt_df = relt_df[['text', 'relational_score']]\n",
    "print(\"Number of cases:\", str(X_relt.shape[0]))\n",
    "\n",
    "valueArray = relt_df.values\n",
    "Y = valueArray[:,1]\n",
    "Y = Y.astype('float')\n",
    "print(\"Number of codes (should match):\", str(len(Y)))\n",
    "\n",
    "test_size = 0.2\n",
    "seed = 3\n",
    "X_train, X_validate, Y_train, Y_validate = train_test_split(X_relt, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "print(f'Y_train Distribution: {Counter(Y_train).most_common()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train: Counter({0.0: 229, 1.0: 114})\n",
      "Y_resample: Counter({1.0: 229, 0.0: 229})\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Oversample to desirable ratio\n",
    "######################################################\n",
    "\n",
    "X_balanced, Y_balanced = resample_data(\n",
    "    X_relt, Y, \n",
    "    undersample=undersample, \n",
    "    sampling_ratio=sampling_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors (KNN):\n",
      "\n",
      "Mean (std):\t 0.6725 (0.4693)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[144  85]\n",
      " [  6 223]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.63      0.76       229\n",
      "         1.0       0.72      0.97      0.83       229\n",
      "\n",
      "    accuracy                           0.80       458\n",
      "   macro avg       0.84      0.80      0.80       458\n",
      "weighted avg       0.84      0.80      0.80       458\n",
      "\n",
      "\n",
      "Random Forest (RF):\n",
      "\n",
      "Mean (std):\t 0.4891 (0.4999)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[224   5]\n",
      " [ 10 219]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97       229\n",
      "         1.0       0.98      0.96      0.97       229\n",
      "\n",
      "    accuracy                           0.97       458\n",
      "   macro avg       0.97      0.97      0.97       458\n",
      "weighted avg       0.97      0.97      0.97       458\n",
      "\n",
      "\n",
      "Decision Tree (DT):\n",
      "\n",
      "Mean (std):\t 0.5371 (0.4986)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[200  29]\n",
      " [ 12 217]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.87      0.91       229\n",
      "         1.0       0.88      0.95      0.91       229\n",
      "\n",
      "    accuracy                           0.91       458\n",
      "   macro avg       0.91      0.91      0.91       458\n",
      "weighted avg       0.91      0.91      0.91       458\n",
      "\n",
      "\n",
      "Multinomial Naive Bayes (MNB):\n",
      "\n",
      "Mean (std):\t 0.6747 (0.4685)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[145  84]\n",
      " [  4 225]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.63      0.77       229\n",
      "         1.0       0.73      0.98      0.84       229\n",
      "\n",
      "    accuracy                           0.81       458\n",
      "   macro avg       0.85      0.81      0.80       458\n",
      "weighted avg       0.85      0.81      0.80       458\n",
      "\n",
      "\n",
      "Logistic Regression (LR):\n",
      "\n",
      "Mean (std):\t 0.4891 (0.4999)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[221   8]\n",
      " [ 13 216]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.95       229\n",
      "         1.0       0.96      0.94      0.95       229\n",
      "\n",
      "    accuracy                           0.95       458\n",
      "   macro avg       0.95      0.95      0.95       458\n",
      "weighted avg       0.95      0.95      0.95       458\n",
      "\n",
      "\n",
      "Support Vector Machine (SVM):\n",
      "\n",
      "Mean (std):\t 0.6266 (0.4837)\n",
      "Accuracy:\t {0, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 80 149]\n",
      " [ 91 138]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.35      0.40       229\n",
      "         1.0       0.48      0.60      0.53       229\n",
      "\n",
      "    accuracy                           0.48       458\n",
      "   macro avg       0.47      0.48      0.47       458\n",
      "weighted avg       0.47      0.48      0.47       458\n",
      "\n",
      "\n",
      "Multi-Layer Perceptron (MLP):\n",
      "\n",
      "Mean (std):\t 0.5109 (0.4999)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[217  12]\n",
      " [  7 222]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96       229\n",
      "         1.0       0.95      0.97      0.96       229\n",
      "\n",
      "    accuracy                           0.96       458\n",
      "   macro avg       0.96      0.96      0.96       458\n",
      "weighted avg       0.96      0.96      0.96       458\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Use different algorithms to build models\n",
    "######################################################\n",
    "\n",
    "models = []\n",
    "models.append(('K-Nearest Neighbors (KNN)', KNeighborsClassifier()))\n",
    "models.append(('Random Forest (RF)', RandomForestClassifier(random_state=seed)))\n",
    "models.append(('Decision Tree (DT)', DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('Multinomial Naive Bayes (MNB)', MultinomialNB()))\n",
    "models.append(('Logistic Regression (LR)', LogisticRegression(random_state=seed)))\n",
    "models.append(('Support Vector Machine (SVM)', SVC(gamma='auto')))\n",
    "models.append(('Multi-Layer Perceptron (MLP)', MLPClassifier(max_iter=100, activation='relu')))\n",
    "\n",
    "# Evaluate algorithms using 10-fold cross validation\n",
    "results, names = show_kfold_output(models=models, \n",
    "                                   X=X_balanced, \n",
    "                                   Y=Y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/work/classification/models/classifier_relt_MLP_012221.joblib']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################\n",
    "# Save best model\n",
    "######################################################\n",
    "\n",
    "relt_model = MLPClassifier(max_iter=100, activation='relu').fit(X_balanced, Y_balanced) # DecisionTreeClassifier(random_state=seed).fit(X_relt, Y) # RandomForestClassifier(random_state=seed).fit(X_balanced, Y_balanced)\n",
    "joblib.dump(relt_model, relt_model_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation step: Use selected model to predict class probabilities in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "Predicting: relational persp.: 100%|██████████| 343/343 [00:07<00:00, 46.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "relt_model = MLPClassifier(max_iter=100, activation='relu').fit(X_relt, Y) # DecisionTreeClassifier(random_state=seed).fit(X_relt, Y)\n",
    "tqdm.pandas(desc = \"Predicting: relational persp.\")\n",
    "relt_df[['prediction_relt','prediction_relt_prob_yes','prediction_relt_prob_no']] = relt_df['text'].progress_apply(lambda sentlist: pd.Series(compute_predictions([' '.join(sent) for sent in sentlist], relt_vectorizer, relt_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "no     238\n",
       "yes    105\n",
       "Name: prediction_relt, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out predictions: labels should be balanced\n",
    "pred_col = 'prediction_relt'\n",
    "relt_df[pred_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of labeled cultural data: [(0.0, 229), (1.0, 114)]\n"
     ]
    }
   ],
   "source": [
    "# Compare to distribution of labeled data\n",
    "print(f'Distribution of labeled cultural data: {Counter(Y).most_common()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc4e10fa438>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check out predicted probabilities: Distribution should be balanced\n",
    "prob_col = 'prediction_relt_prob_yes'\n",
    "relt_df[prob_col].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate algorithms: Demographic perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases: 349\n",
      "Number of codes (should match): 349\n",
      "Y_train Distribution: [(0.0, 195), (1.0, 84)]\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Prepare training and validation data\n",
    "######################################################\n",
    "\n",
    "# Separate training and final validation data set. First reltove class\n",
    "# label from data (X). Setup target class (Y)\n",
    "# Then make the validation set 10% of the entire\n",
    "# set of labeled data (X_validate, Y_validate)\n",
    "\n",
    "demog_df = demog_df[['text', 'demographic_score']]\n",
    "print(\"Number of cases:\", str(X_demog.shape[0]))\n",
    "\n",
    "valueArray = demog_df.values\n",
    "Y = valueArray[:,1]\n",
    "Y = Y.astype('float')\n",
    "print(\"Number of codes (should match):\", str(len(Y)))\n",
    "\n",
    "test_size = 0.2\n",
    "seed = 3\n",
    "X_train, X_validate, Y_train, Y_validate = train_test_split(X_demog, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "print(f'Y_train Distribution: {Counter(Y_train).most_common()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train: Counter({0.0: 248, 1.0: 101})\n",
      "Y_resample: Counter({1.0: 248, 0.0: 248})\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Oversample to desirable ratio\n",
    "######################################################\n",
    "\n",
    "X_balanced, Y_balanced = resample_data(\n",
    "    X_demog, Y, \n",
    "    undersample=undersample, \n",
    "    sampling_ratio=sampling_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors (KNN):\n",
      "\n",
      "Mean (std):\t 0.629 (0.4831)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[181  67]\n",
      " [  3 245]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.73      0.84       248\n",
      "         1.0       0.79      0.99      0.88       248\n",
      "\n",
      "    accuracy                           0.86       496\n",
      "   macro avg       0.88      0.86      0.86       496\n",
      "weighted avg       0.88      0.86      0.86       496\n",
      "\n",
      "\n",
      "Random Forest (RF):\n",
      "\n",
      "Mean (std):\t 0.502 (0.5)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[243   5]\n",
      " [  4 244]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98       248\n",
      "         1.0       0.98      0.98      0.98       248\n",
      "\n",
      "    accuracy                           0.98       496\n",
      "   macro avg       0.98      0.98      0.98       496\n",
      "weighted avg       0.98      0.98      0.98       496\n",
      "\n",
      "\n",
      "Decision Tree (DT):\n",
      "\n",
      "Mean (std):\t 0.5464 (0.4978)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[218  30]\n",
      " [  7 241]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.88      0.92       248\n",
      "         1.0       0.89      0.97      0.93       248\n",
      "\n",
      "    accuracy                           0.93       496\n",
      "   macro avg       0.93      0.93      0.93       496\n",
      "weighted avg       0.93      0.93      0.93       496\n",
      "\n",
      "\n",
      "Multinomial Naive Bayes (MNB):\n",
      "\n",
      "Mean (std):\t 0.6391 (0.4803)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[179  69]\n",
      " [  0 248]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.72      0.84       248\n",
      "         1.0       0.78      1.00      0.88       248\n",
      "\n",
      "    accuracy                           0.86       496\n",
      "   macro avg       0.89      0.86      0.86       496\n",
      "weighted avg       0.89      0.86      0.86       496\n",
      "\n",
      "\n",
      "Logistic Regression (LR):\n",
      "\n",
      "Mean (std):\t 0.506 (0.5)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[241   7]\n",
      " [  4 244]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.98       248\n",
      "         1.0       0.97      0.98      0.98       248\n",
      "\n",
      "    accuracy                           0.98       496\n",
      "   macro avg       0.98      0.98      0.98       496\n",
      "weighted avg       0.98      0.98      0.98       496\n",
      "\n",
      "\n",
      "Support Vector Machine (SVM):\n",
      "\n",
      "Mean (std):\t 0.6996 (0.4584)\n",
      "Accuracy:\t {0, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[ 62 186]\n",
      " [ 87 161]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.25      0.31       248\n",
      "         1.0       0.46      0.65      0.54       248\n",
      "\n",
      "    accuracy                           0.45       496\n",
      "   macro avg       0.44      0.45      0.43       496\n",
      "weighted avg       0.44      0.45      0.43       496\n",
      "\n",
      "\n",
      "Multi-Layer Perceptron (MLP):\n",
      "\n",
      "Mean (std):\t 0.502 (0.5)\n",
      "Accuracy:\t {1, 4}\n",
      "\n",
      "Confusion matrix:\n",
      " [[245   3]\n",
      " [  2 246]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99       248\n",
      "         1.0       0.99      0.99      0.99       248\n",
      "\n",
      "    accuracy                           0.99       496\n",
      "   macro avg       0.99      0.99      0.99       496\n",
      "weighted avg       0.99      0.99      0.99       496\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Use different algorithms to build models\n",
    "######################################################\n",
    "\n",
    "models = []\n",
    "models.append(('K-Nearest Neighbors (KNN)', KNeighborsClassifier()))\n",
    "models.append(('Random Forest (RF)', RandomForestClassifier(random_state=seed)))\n",
    "models.append(('Decision Tree (DT)', DecisionTreeClassifier(random_state=seed)))\n",
    "models.append(('Multinomial Naive Bayes (MNB)', MultinomialNB()))\n",
    "models.append(('Logistic Regression (LR)', LogisticRegression(random_state=seed)))\n",
    "models.append(('Support Vector Machine (SVM)', SVC(gamma='auto')))\n",
    "models.append(('Multi-Layer Perceptron (MLP)', MLPClassifier(max_iter=100, activation='relu')))\n",
    "\n",
    "# Evaluate algorithms using 10-fold cross validation\n",
    "results, names = show_kfold_output(models=models, \n",
    "                                   X=X_balanced, \n",
    "                                   Y=Y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/work/classification/models/classifier_demog_MLP_012221.joblib']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################\n",
    "# Save best model\n",
    "######################################################\n",
    "\n",
    "demog_model = MLPClassifier(max_iter=100, activation='relu').fit(X_balanced, Y_balanced) # DecisionTreeClassifier(random_state=seed).fit(X_relt, Y) # RandomForestClassifier(random_state=seed).fit(X_balanced, Y_balanced)\n",
    "joblib.dump(demog_model, demog_model_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation step: Use selected model to predict class probabilities in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "Predicting: demographic persp.: 100%|██████████| 349/349 [00:05<00:00, 67.91it/s] \n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "demog_model = MLPClassifier(max_iter=100, activation='relu').fit(X_demog, Y) # RandomForestClassifier(random_state=seed).fit(X_demog, Y)\n",
    "tqdm.pandas(desc = \"Predicting: demographic persp.\")\n",
    "demog_df[['prediction_demog','prediction_demog_prob_yes','prediction_demog_prob_no']] = demog_df['text'].progress_apply(lambda sentlist: pd.Series(compute_predictions([' '.join(sent) for sent in sentlist], demog_vectorizer, demog_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     246\n",
       "yes    103\n",
       "Name: prediction_demog, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out predictions: labels should be balanced\n",
    "pred_col = 'prediction_demog'\n",
    "demog_df[pred_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of labeled demographic data: [(0.0, 248), (1.0, 101)]\n"
     ]
    }
   ],
   "source": [
    "# Compare to distribution of labeled data\n",
    "print(f'Distribution of labeled demographic data: {Counter(Y).most_common()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc4db22f668>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check out predicted probabilities: Distribution should be balanced\n",
    "prob_col = 'prediction_demog_prob_yes'\n",
    "demog_df[prob_col].hist(bins=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
