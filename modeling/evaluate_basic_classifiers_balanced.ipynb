{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare classification methods for identifying Covid-19 myths in tweets\n",
    "## Includes training data balancing\n",
    "\n",
    "@authors: Alexander Chen, Jaren Haber<br>\n",
    "@affiliation: Massive Data Institute, McCourt School of Public Policy, Georgetown University<br>\n",
    "@date: November 4, 2020\n",
    "\n",
    "'''\n",
    "Trains classifiers to predict whether a tweet is about a given coronavirus mtyh. Uses preliminary labeled tweet data (440 per myth) to train classifiers. Compares f1_weighted scores of three model structures using 10-Fold Cross Validation: K-Nearest Neighbors, Random Forest, and Decision Tree. Oversamples training data to .5 (1:2 minority:majority class).\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ac1975/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Import libraries\n",
    "######################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import csv\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Define filepaths\n",
    "######################################################\n",
    "\n",
    "thisday = date.today().strftime(\"%d%m%y\")\n",
    "\n",
    "dis_fp = '../data/myth_disinfectants_sample-440-labeled.csv'\n",
    "rem_fp = '../data/myth_home_remedies_sample-440-labeled.csv'\n",
    "wth_fp = '../data/myth_weather_sample-440-labeled.csv'\n",
    "\n",
    "dis_mod_fp = f'../models/tweet_classifier_disinfectants_{str(thisday)}.joblib'\n",
    "rem_mod_fp = f'../models/tweet_classifier_home_remedies_{str(thisday)}.joblib'\n",
    "wth_mod_fp = f'../models/tweet_classifier_weather_{str(thisday)}.joblib'\n",
    "\n",
    "dis_vec_fp = f'../models/vectorizer_disinfectants_{str(thisday)}.joblib'\n",
    "rem_vec_fp = f'../models/vectorizer_home_remedies_{str(thisday)}.joblib'\n",
    "wth_vec_fp = f'../models/vectorizer_weather_{str(thisday)}.joblib'\n",
    "\n",
    "dis_vec_feat_fp = f'../models/vectorizer_features_disinfectants_{str(thisday)}.csv'\n",
    "rem_vec_feat_fp = f'../models/vectorizer_features_home_remedies_{str(thisday)}.csv'\n",
    "wth_vec_feat_fp = f'../models/vectorizer_features_weather_{str(thisday)}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>rem_is_myth</th>\n",
       "      <th>rem_myth_score</th>\n",
       "      <th>rem_is_myth_supports</th>\n",
       "      <th>rem_myth_supports_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1230594710667837440</td>\n",
       "      <td>@USER01 DJI improves temperature-measuring dro...</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1239221464080871424</td>\n",
       "      <td>Microban 24 Hour Disinfectant Sanitizing Spray...</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1229926198156808192</td>\n",
       "      <td>Travel Tip: Looks like the #coronavirus can su...</td>\n",
       "      <td>no</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>no</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1236415894894424067</td>\n",
       "      <td>Solution to our global pandemic! \\n\\nBut then ...</td>\n",
       "      <td>no</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>no</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1238144576910766080</td>\n",
       "      <td>Now it all makes sense why China was spraying ...</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1234211333937270790</td>\n",
       "      <td>Fear, distrust and disinfectant in the air ami...</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1235148391765757952</td>\n",
       "      <td>Can regularly rinsing your nose with saline he...</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>unsure</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1238600642136100864</td>\n",
       "      <td>The shelves in Walmart are empty. Water, disin...</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1237484894772531205</td>\n",
       "      <td>@USER01 Thank you. I’m still using the spray I...</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1236889906686955520</td>\n",
       "      <td>Would you get a disinfectant service at your h...</td>\n",
       "      <td>no</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>no</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1230594710667837440  @USER01 DJI improves temperature-measuring dro...   \n",
       "1  1239221464080871424  Microban 24 Hour Disinfectant Sanitizing Spray...   \n",
       "2  1229926198156808192  Travel Tip: Looks like the #coronavirus can su...   \n",
       "3  1236415894894424067  Solution to our global pandemic! \\n\\nBut then ...   \n",
       "4  1238144576910766080  Now it all makes sense why China was spraying ...   \n",
       "5  1234211333937270790  Fear, distrust and disinfectant in the air ami...   \n",
       "6  1235148391765757952  Can regularly rinsing your nose with saline he...   \n",
       "7  1238600642136100864  The shelves in Walmart are empty. Water, disin...   \n",
       "8  1237484894772531205  @USER01 Thank you. I’m still using the spray I...   \n",
       "9  1236889906686955520  Would you get a disinfectant service at your h...   \n",
       "\n",
       "  rem_is_myth  rem_myth_score rem_is_myth_supports  rem_myth_supports_score  \n",
       "0          no        1.000000                   no                 1.000000  \n",
       "1          no        1.000000                   no                 1.000000  \n",
       "2          no        0.666667                   no                 0.666667  \n",
       "3          no        0.666667                   no                 0.666667  \n",
       "4          no        1.000000                   no                 1.000000  \n",
       "5          no        1.000000                   no                 1.000000  \n",
       "6         yes        1.000000               unsure                 1.000000  \n",
       "7          no        1.000000                   no                 1.000000  \n",
       "8          no        1.000000                   no                 1.000000  \n",
       "9          no        0.666667                   no                 0.666667  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################\n",
    "# Load and rename the data\n",
    "######################################################\n",
    "\n",
    "dis_df = pd.read_csv(dis_fp, low_memory=False)\n",
    "rem_df = pd.read_csv(rem_fp, low_memory=False)\n",
    "wth_df = pd.read_csv(wth_fp, low_memory=False)\n",
    "\n",
    "# Rename each DF's myth columns for clarity\n",
    "dis_df.rename(inplace = True, copy = False, \n",
    "              columns = {'is_myth': 'dis_is_myth', 'myth_score': 'dis_myth_score', \n",
    "                         'is_myth_supports': 'dis_is_myth_supports', 'myth_supports_score': 'dis_myth_supports_score'}\n",
    "             )\n",
    "rem_df.rename(inplace = True, copy = False, \n",
    "              columns = {'is_myth': 'rem_is_myth', 'myth_score': 'rem_myth_score', \n",
    "                         'is_myth_supports': 'rem_is_myth_supports', 'myth_supports_score': 'rem_myth_supports_score'}\n",
    "             )\n",
    "wth_df.rename(inplace = True, copy = False, \n",
    "              columns = {'is_myth': 'wth_is_myth', 'myth_score': 'wth_myth_score', \n",
    "                         'is_myth_supports': 'wth_is_myth_supports', 'myth_supports_score': 'wth_myth_supports_score'}\n",
    "             )\n",
    "\n",
    "rem_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dis_is_myth\n",
      "no     413\n",
      "yes     27\n",
      "dtype: int64\n",
      "\n",
      "rem_is_myth\n",
      "no     406\n",
      "yes     34\n",
      "dtype: int64\n",
      "\n",
      "wth_is_myth\n",
      "no      21\n",
      "yes    419\n",
      "dtype: int64\n",
      "\n",
      "dis_is_myth_supports\n",
      "no        434\n",
      "unsure      4\n",
      "yes         2\n",
      "dtype: int64\n",
      "\n",
      "rem_is_myth_supports\n",
      "no        417\n",
      "unsure      9\n",
      "yes        14\n",
      "dtype: int64\n",
      "\n",
      "wth_is_myth_supports\n",
      "no        195\n",
      "unsure    106\n",
      "yes       139\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Summarize the numerical data\n",
    "######################################################\n",
    "\n",
    "# Look at the number of instances of each is_myth\n",
    "# class distribution\n",
    "print(dis_df.groupby('dis_is_myth').size())\n",
    "print()\n",
    "print(rem_df.groupby('rem_is_myth').size())\n",
    "print()\n",
    "print(wth_df.groupby('wth_is_myth').size())\n",
    "print()\n",
    "\n",
    "# Look at the number of instances of each is_myth_supports class distribution\n",
    "print(dis_df.groupby('dis_is_myth_supports').size())\n",
    "print()\n",
    "print(rem_df.groupby('rem_is_myth_supports').size())\n",
    "print()\n",
    "print(wth_df.groupby('wth_is_myth_supports').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tweet on home remedies 1:\n",
      " @USER01 DJI improves temperature-measuring drones with a simple cotton swab\n",
      "DJI drones have been helping tackle the coronavirus outbreak with temperature screening and disinfectant spray\n",
      "<em>URL01 Removed</em>\n",
      "#COVID19\n",
      "#新冠病毒\n",
      "#武汉肺炎\n",
      "\n",
      "Example tweet on home remedies 2:\n",
      " Microban 24 Hour Disinfectant Sanitizing Spray Citrus Scent 15 fl oz Surface <em>URL01 Removed</em> #coronavirus #covid_19 #covid19 <em>URL02 Removed</em>\n",
      "\n",
      "Vocab size: 3275\n",
      "\n",
      "20 most frequent words in raw home remedies tweets:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('#', 2159),\n",
       " ('<', 706),\n",
       " ('>', 706),\n",
       " ('.', 422),\n",
       " (',', 385),\n",
       " ('em', 353),\n",
       " ('Removed', 353),\n",
       " ('/em', 353),\n",
       " ('URL01', 317),\n",
       " ('coronavirus', 314),\n",
       " ('the', 296),\n",
       " ('disinfectant', 293),\n",
       " (':', 252),\n",
       " ('to', 214),\n",
       " ('of', 199),\n",
       " ('and', 179),\n",
       " ('@', 164),\n",
       " ('in', 149),\n",
       " ('Disinfectant', 144),\n",
       " ('CoronavirusOutbreak', 139)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################\n",
    "# Summarize the text data\n",
    "######################################################\n",
    "\n",
    "# See examples of two tweets\n",
    "# Note that usernames and URLs have already been replaced, but hashtags remain\n",
    "print(\"Example tweet on home remedies 1:\\n\", rem_df['text'][0])\n",
    "print()\n",
    "print(\"Example tweet on home remedies 2:\\n\", rem_df['text'][1])\n",
    "print()\n",
    "\n",
    "# Look at size of vocabulary\n",
    "# Add words from each tweet to empty list:\n",
    "tweet_tokens = []; rem_df['text'].apply(lambda x: tweet_tokens.extend(word_tokenize(x)))\n",
    "print('Vocab size:', len(set(tweet_tokens)))\n",
    "print()\n",
    "\n",
    "# Check out most frequent words in unprocessed text\n",
    "freq = Counter(tweet_tokens)\n",
    "print('20 most frequent words in raw home remedies tweets:')\n",
    "freq.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Tweet Preprocessing\n",
    "######################################################\n",
    "\n",
    "def process_tweets(tweet):\n",
    "    '''\n",
    "    Preprocesses raw text of a tweet by lower-casing, stripping whitespace, \n",
    "    \n",
    "    args:\n",
    "        tweet: raw text of a tweet\n",
    "    '''\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove URL signifiers like '<em>URL01 Removed</em>'\n",
    "    url_pattern = r'<em>url\\d{2}\\sremoved<\\/em>'\n",
    "    tweet = re.sub(url_pattern, '', tweet)\n",
    "    \n",
    "    # Remove username signifiers like '@USER01'\n",
    "    user_pattern = r'@user\\d{2}'\n",
    "    tweet = re.sub(user_pattern, '', tweet)\n",
    "        \n",
    "    # Remove additional white spaces\n",
    "    whitespace_pattern = r'\\s+'\n",
    "    tweet = re.sub(whitespace_pattern, ' ', tweet) # strip whitespaces in between words\n",
    "    tweet = tweet.strip() # strip whitespaces at start & end\n",
    "    \n",
    "    # Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    \n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"]+\", flags = re.UNICODE)\n",
    "    tweet = re.sub(emoji_pattern, '', tweet)\n",
    "    \n",
    "    # Lemmatization\n",
    "    tweet = tweet.split()\n",
    "    tweet = ' '.join([stemmer.lemmatize(word) for word in tweet])\n",
    "        \n",
    "    return tweet\n",
    "\n",
    "\n",
    "dis_df['text_cleaned'] = dis_df['text'].apply(lambda x: process_tweets(x))\n",
    "rem_df['text_cleaned'] = rem_df['text'].apply(lambda x: process_tweets(x))\n",
    "wth_df['text_cleaned'] = wth_df['text'].apply(lambda x: process_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tweet on home remedies 1 (cleaned):\n",
      " dji improves temperature-measuring drone with a simple cotton swab dji drone have been helping tackle the coronavirus outbreak with temperature screening and disinfectant spray covid19 新冠病毒 武汉肺炎\n",
      "\n",
      "Example tweet on home remedies 2 (cleaned):\n",
      " microban 24 hour disinfectant sanitizing spray citrus scent 15 fl oz surface coronavirus covid_19 covid19\n",
      "\n",
      "Vocabulary sizes for preprocessed tweets labeled for each myth:\n",
      "Disinfectants: 2769\n",
      "Home remedies: 2716\n",
      "Weather: 2694\n",
      "\n",
      "20 most frequent words in cleaned home remedies tweets:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('disinfectant', 445),\n",
       " ('coronavirus', 406),\n",
       " ('.', 400),\n",
       " (',', 385),\n",
       " ('the', 330),\n",
       " (':', 252),\n",
       " ('to', 223),\n",
       " ('of', 203),\n",
       " ('a', 198),\n",
       " ('and', 182),\n",
       " ('in', 155),\n",
       " ('coronavirusoutbreak', 145),\n",
       " ('spray', 133),\n",
       " ('covid19', 121),\n",
       " ('virus', 119),\n",
       " ('on', 109),\n",
       " ('for', 109),\n",
       " ('coronaoutbreak', 108),\n",
       " ('with', 106),\n",
       " ('flu', 100)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take another look at first two tweets (after preprocessing)\n",
    "print(\"Example tweet on home remedies 1 (cleaned):\\n\", rem_df['text_cleaned'][0])\n",
    "print()\n",
    "print(\"Example tweet on home remedies 2 (cleaned):\\n\", rem_df['text_cleaned'][1])\n",
    "print()\n",
    "\n",
    "# Check out vocab size after cleaning\n",
    "# Add words from each cleaned tweet to empty list:\n",
    "tweet_tokens_cleaned_dis = []; dis_df['text_cleaned'].apply(lambda x: tweet_tokens_cleaned_dis.extend(word_tokenize(x))) \n",
    "tweet_tokens_cleaned_rem = []; rem_df['text_cleaned'].apply(lambda x: tweet_tokens_cleaned_rem.extend(word_tokenize(x))) \n",
    "tweet_tokens_cleaned_wth = []; wth_df['text_cleaned'].apply(lambda x: tweet_tokens_cleaned_wth.extend(word_tokenize(x))) \n",
    "print(\"Vocabulary sizes for preprocessed tweets labeled for each myth:\")\n",
    "print('Disinfectants:', len(set(tweet_tokens_cleaned_dis)))\n",
    "print('Home remedies:', len(set(tweet_tokens_cleaned_rem)))\n",
    "print('Weather:', len(set(tweet_tokens_cleaned_wth)))\n",
    "print()\n",
    "\n",
    "# Check out most frequent words in preprocessed text\n",
    "freq = Counter(tweet_tokens_cleaned_rem)\n",
    "print('20 most frequent words in cleaned home remedies tweets:')\n",
    "freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in vectorizer (total vocabulary): 2421\n",
      "\n",
      "['00', 'agree', 'attributable', 'bu', 'clinics', 'coronaviruspakistan', 'december', 'dude', 'export', 'garlic', 'help', 'indonesia', 'kong', 'magical', 'myanmar', 'page', 'predictions', 'red', 'sauna', 'slows', 'strand', 'tent', 'trustworthy', 'vxx', 'wuhanflu']\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Vectorize text\n",
    "######################################################\n",
    "\n",
    "# Use TFIDF weighted DTM because does better overall than unweighted\n",
    "#vectorizer = CountVectorizer(max_features=10000, min_df=1, max_df=0.8, stop_words=stopwords.words('english')) # DTM\n",
    "vectorizer = TfidfVectorizer(max_features=10000, min_df=1, max_df=0.8, stop_words=stopwords.words('english')) # TFIDF\n",
    "\n",
    "# creates sparse DTM X\n",
    "# use X.toarray() to get with zero representation\n",
    "\n",
    "dis_tweets, rem_tweets, wth_tweets = [], [], [] # empty list to add tweets to\n",
    "dis_df['text_cleaned'].apply(lambda x: dis_tweets.append(x)) # add tweet from each row of DF\n",
    "rem_df['text_cleaned'].apply(lambda x: rem_tweets.append(x)) # add tweet from each row of DF\n",
    "wth_df['text_cleaned'].apply(lambda x: wth_tweets.append(x)) # add tweet from each row of DF\n",
    "\n",
    "X_dis = vectorizer.fit_transform(dis_tweets)\n",
    "joblib.dump(vectorizer, open(dis_vec_fp, \"wb\"))\n",
    "with open(dis_vec_feat_fp,'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows([vectorizer.get_feature_names()])\n",
    "\n",
    "X_rem = vectorizer.fit_transform(rem_tweets)\n",
    "joblib.dump(vectorizer, open(rem_vec_fp, \"wb\"))\n",
    "with open(rem_vec_feat_fp,'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows([vectorizer.get_feature_names()])\n",
    "\n",
    "X_wth = vectorizer.fit_transform(wth_tweets)\n",
    "joblib.dump(vectorizer, open(wth_vec_fp, \"wb\"))\n",
    "with open(wth_vec_feat_fp,'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows([vectorizer.get_feature_names()])\n",
    "\n",
    "print('Number of features in vectorizer (total vocabulary):', len(vectorizer.get_feature_names()))\n",
    "print()\n",
    "\n",
    "print(vectorizer.get_feature_names()[::100]) # get every 100th word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Specify the data\n",
    "######################################################\n",
    "\n",
    "dis_df_is_myth = dis_df[['text_cleaned','dis_is_myth']]\n",
    "rem_df_is_myth = rem_df[['text_cleaned','rem_is_myth']]\n",
    "wth_df_is_myth = wth_df[['text_cleaned','wth_is_myth']]\n",
    "\n",
    "dis_df_is_myth_supports = dis_df[['text_cleaned','dis_is_myth_supports']].copy()\n",
    "rem_df_is_myth_supports = rem_df[['text_cleaned','rem_is_myth_supports']].copy()\n",
    "wth_df_is_myth_supports = wth_df[['text_cleaned','wth_is_myth_supports']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Convert No/Yes to [0,1]\n",
    "######################################################\n",
    "\n",
    "def no_yes_convert(convert_df, column_name, has_unsure = False):\n",
    "    '''\n",
    "    args\n",
    "        convert_df: df containing column to convert\n",
    "        column_name: column to convert from 'yes','no','unsure' to float. Scoring scheme:\n",
    "            no: 0\n",
    "            unsure: 0.5\n",
    "            yes: 1\n",
    "        has_unsure: boolean, indicates whether convert_df has 'unsure' in column_name\n",
    "    '''\n",
    "    \n",
    "    # Already converted to float\n",
    "    if convert_df[column_name].dtype == 'float64':\n",
    "        return convert_df\n",
    "    \n",
    "    new_df = convert_df.loc[:, convert_df.columns != column_name]\n",
    "    \n",
    "    for num in range(0,len(new_df)):\n",
    "        row_index = new_df.index[num]\n",
    "        \n",
    "        if convert_df.loc[num,column_name] == 'no':\n",
    "            new_df.loc[row_index,column_name] = 0.0\n",
    "            \n",
    "        elif convert_df.loc[num,column_name] == 'yes':\n",
    "            new_df.loc[row_index,column_name] = 1.0\n",
    "            \n",
    "        elif has_unsure == True and convert_df.loc[num,column_name] == 'unsure':\n",
    "            new_df.loc[row_index,column_name] = 0.5\n",
    "            \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home remedies categories in raw data:\n",
      "no     406\n",
      "yes     34\n",
      "Name: rem_is_myth, dtype: int64\n",
      "\n",
      "Home remedies cleaned up:\n",
      "0.0    406\n",
      "1.0     34\n",
      "Name: rem_is_myth, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Convert myData_is_myth to float\n",
    "######################################################\n",
    "\n",
    "dis_df_is_myth = no_yes_convert(dis_df_is_myth,'dis_is_myth')\n",
    "rem_df_is_myth = no_yes_convert(rem_df_is_myth,'rem_is_myth')\n",
    "wth_df_is_myth = no_yes_convert(wth_df_is_myth,'wth_is_myth')\n",
    "\n",
    "print(\"Home remedies categories in raw data:\")\n",
    "print(rem_df['rem_is_myth'].value_counts())\n",
    "print()\n",
    "print(\"Home remedies cleaned up:\")\n",
    "print(rem_df_is_myth['rem_is_myth'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Balance x_train, y_train\n",
    "######################################################\n",
    "\n",
    "def resample_data(X_train, Y_train, undersample, sampling_strategy):\n",
    "    \"\"\"\n",
    "    args\n",
    "        X_train: X training data\n",
    "        Y_train: Y training data\n",
    "        undersmample: boolean for over or undersampling\n",
    "        sampling_strategy: strategy for resampled distribution\n",
    "            if oversample: 'majority' makes minority = to majority\n",
    "            if undersample: 'minority' makes majority = to minority\n",
    "    \"\"\"\n",
    "    \n",
    "    if undersample == True:\n",
    "        undersample = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
    "        X_balanced, Y_balanced = undersample.fit_resample(X_train, Y_train)\n",
    "    else:\n",
    "        oversample = RandomOverSampler(sampling_strategy=sampling_strategy)\n",
    "        X_balanced, Y_balanced = oversample.fit_resample(X_train, Y_train)\n",
    "    \n",
    "    print(f'Y_train: {Counter(Y_train)}\\nY_resample: {Counter(Y_balanced)}')\n",
    "    \n",
    "    return X_balanced, Y_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate algorithms: Disinfectants myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train Distribution: [(0.0, 331), (1.0, 21)]\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Prepare training and validation data\n",
    "######################################################\n",
    "\n",
    "# Separate training and final validation data set. First remove class\n",
    "# label from data (X). Setup target class (Y)\n",
    "# Then make the validation set 10% of the entire\n",
    "# set of labeled data (X_validate, Y_validate)\n",
    "\n",
    "valueArray = dis_df_is_myth.values\n",
    "Y = valueArray[:,1]\n",
    "Y = Y.astype('float')\n",
    "test_size = 0.2\n",
    "seed = 3\n",
    "X_train, X_validate, Y_train, Y_validate = train_test_split(X_dis, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "print(f'Y_train Distribution: {Counter(Y_train).most_common()}')\n",
    "\n",
    "# Setup 10-fold cross validation to estimate the accuracy of different models\n",
    "# Split data into 10 parts\n",
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "# num_instances = len(X_train)\n",
    "seed = 7\n",
    "scoring='f1_weighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train: Counter({0.0: 331, 1.0: 21})\n",
      "Y_resample: Counter({0.0: 331, 1.0: 165})\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Undersample to minority size\n",
    "######################################################\n",
    "sampling_strategy = .5\n",
    "undersample = False\n",
    "\n",
    "X_balanced, Y_balanced = resample_data(X_train, Y_train, undersample=undersample, sampling_strategy=sampling_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Fold Cross Validation: Disinfectants myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.9643, (0.0291)\n",
      "RF: 1.0, (0.0)\n",
      "DT: 0.9879, (0.0161)\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Use different algorithms to build models\n",
    "######################################################\n",
    "\n",
    "# Add each algorithm and its name to the model array\n",
    "models = []\n",
    "models.append(('KNN',KNeighborsClassifier()))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=1000, random_state=0)))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "\n",
    "# Evaluate each model, add results to a results array,\n",
    "# Print the accuracy results (remember these are averages and std)\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_balanced, Y_balanced, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f'{name}: {round(cv_results.mean(),4)}, ({round(cv_results.std(),4)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN: Disinfectants myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unbalanced Classifier [(0.0, 331), (1.0, 21)]\n",
      "0.9659090909090909\n",
      "[[82  0]\n",
      " [ 3  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98        82\n",
      "         1.0       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.97        88\n",
      "   macro avg       0.98      0.75      0.82        88\n",
      "weighted avg       0.97      0.97      0.96        88\n",
      "\n",
      "\n",
      "Balanced Classifier [(0.0, 331), (1.0, 165)]\n",
      "0.9318181818181818\n",
      "[[77  5]\n",
      " [ 1  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.94      0.96        82\n",
      "         1.0       0.50      0.83      0.62         6\n",
      "\n",
      "    accuracy                           0.93        88\n",
      "   macro avg       0.74      0.89      0.79        88\n",
      "weighted avg       0.95      0.93      0.94        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Compare algorithms on validation test: KNN\n",
    "######################################################\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "knn_dis = KNeighborsClassifier()\n",
    "knn_dis.fit(X_train, Y_train)\n",
    "knn_predictions = knn_dis.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Unbalanced Classifier {Counter(Y_train).most_common()}')\n",
    "print(accuracy_score(Y_validate, knn_predictions))\n",
    "print(confusion_matrix(Y_validate, knn_predictions))\n",
    "print(classification_report(Y_validate, knn_predictions))\n",
    "\n",
    "######################################################\n",
    "# Balanced: Compare algorithms on validation test: KNN\n",
    "######################################################\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "knn_dis = KNeighborsClassifier()\n",
    "knn_dis.fit(X_balanced, Y_balanced)\n",
    "knn_predictions = knn_dis.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Balanced Classifier {Counter(Y_balanced).most_common()}')\n",
    "print(accuracy_score(Y_validate, knn_predictions))\n",
    "print(confusion_matrix(Y_validate, knn_predictions))\n",
    "print(classification_report(Y_validate, knn_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest: Disinfectants myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unbalanced Classifier [(0.0, 331), (1.0, 21)]\n",
      "0.9545454545454546\n",
      "[[82  0]\n",
      " [ 4  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.98        82\n",
      "         1.0       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.95        88\n",
      "   macro avg       0.98      0.67      0.74        88\n",
      "weighted avg       0.96      0.95      0.94        88\n",
      "\n",
      "\n",
      "Balanced Classifier [(0.0, 331), (1.0, 165)]\n",
      "0.9772727272727273\n",
      "[[82  0]\n",
      " [ 2  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99        82\n",
      "         1.0       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98        88\n",
      "   macro avg       0.99      0.83      0.89        88\n",
      "weighted avg       0.98      0.98      0.98        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Compare algorithms on validation test: Random Forest\n",
    "######################################################\n",
    "\n",
    "rf_dis = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "rf_dis.fit(X_train, Y_train) \n",
    "rf_predictions = rf_dis.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Unbalanced Classifier {Counter(Y_train).most_common()}')\n",
    "print(accuracy_score(Y_validate, rf_predictions))\n",
    "print(confusion_matrix(Y_validate, rf_predictions))\n",
    "print(classification_report(Y_validate, rf_predictions))\n",
    "\n",
    "######################################################\n",
    "# Balanced: Compare algorithms on validation test: Random Forest\n",
    "######################################################\n",
    "rf_dis = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "rf_dis.fit(X_balanced, Y_balanced) \n",
    "rf_predictions = rf_dis.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Balanced Classifier {Counter(Y_balanced).most_common()}')\n",
    "print(accuracy_score(Y_validate, rf_predictions))\n",
    "print(confusion_matrix(Y_validate, rf_predictions))\n",
    "print(classification_report(Y_validate, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Disinfectants myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unbalanced Classifier [(0.0, 331), (1.0, 21)]\n",
      "0.9886363636363636\n",
      "[[82  0]\n",
      " [ 1  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99        82\n",
      "         1.0       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99        88\n",
      "   macro avg       0.99      0.92      0.95        88\n",
      "weighted avg       0.99      0.99      0.99        88\n",
      "\n",
      "\n",
      "Balanced Classifier [(0.0, 331), (1.0, 165)]\n",
      "0.9886363636363636\n",
      "[[82  0]\n",
      " [ 1  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99        82\n",
      "         1.0       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99        88\n",
      "   macro avg       0.99      0.92      0.95        88\n",
      "weighted avg       0.99      0.99      0.99        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Compare algorithms on validation test: Decision Tree\n",
    "######################################################\n",
    "\n",
    "dt_dis = DecisionTreeClassifier()\n",
    "dt_dis.fit(X_train, Y_train)\n",
    "dt_predictions = dt_dis.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Unbalanced Classifier {Counter(Y_train).most_common()}')\n",
    "print(accuracy_score(Y_validate, dt_predictions))\n",
    "print(confusion_matrix(Y_validate, dt_predictions))\n",
    "print(classification_report(Y_validate, dt_predictions))\n",
    "\n",
    "######################################################\n",
    "# Balanced: Compare algorithms on validation test: Decision Tree\n",
    "######################################################\n",
    "dt_dis = DecisionTreeClassifier()\n",
    "dt_dis.fit(X_balanced, Y_balanced)\n",
    "dt_predictions = dt_dis.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Balanced Classifier {Counter(Y_balanced).most_common()}')\n",
    "print(accuracy_score(Y_validate, dt_predictions))\n",
    "print(confusion_matrix(Y_validate, dt_predictions))\n",
    "print(classification_report(Y_validate, dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Save best model\n",
    "######################################################\n",
    "\n",
    "# joblib.dump(rf_dis, dis_mod_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate algorithms: Home remedies myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train Distribution: [(0.0, 324), (1.0, 28)]\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Prepare training and validation data\n",
    "######################################################\n",
    "\n",
    "# Separate training and final validation data set. First remove class\n",
    "# label from data (X). Setup target class (Y)\n",
    "# Then make the validation set 10% of the entire\n",
    "# set of labeled data (X_validate, Y_validate)\n",
    "\n",
    "valueArray = rem_df_is_myth.values\n",
    "Y = valueArray[:,1]\n",
    "Y = Y.astype('float')\n",
    "test_size = 0.2\n",
    "seed = 3\n",
    "X_train, X_validate, Y_train, Y_validate = train_test_split(X_rem, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "print(f'Y_train Distribution: {Counter(Y_train).most_common()}')\n",
    "\n",
    "# Setup 10-fold cross validation to estimate the accuracy of different models\n",
    "# Split data into 10 parts\n",
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "# num_instances = len(X_train)\n",
    "seed = 7\n",
    "scoring = 'f1_weighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train: Counter({0.0: 324, 1.0: 28})\n",
      "Y_resample: Counter({0.0: 324, 1.0: 162})\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Undersample to minority size\n",
    "######################################################\n",
    "sampling_strategy = .5\n",
    "undersample = False\n",
    "\n",
    "X_balanced, Y_balanced = resample_data(X_train, Y_train, undersample=undersample, sampling_strategy=sampling_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Fold Cross Validation: Home remedies myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.9241, (0.0531)\n",
      "RF: 0.9979, (0.0062)\n",
      "DT: 0.9636, (0.0216)\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Use different algorithms to build models\n",
    "######################################################\n",
    "\n",
    "# Add each algorithm and its name to the model array\n",
    "models = []\n",
    "models.append(('KNN',KNeighborsClassifier()))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=1000, random_state=0)))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "\n",
    "# Evaluate each model, add results to a results array,\n",
    "# Print the accuracy results (remember these are averages and std)\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_balanced, Y_balanced, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f'{name}: {round(cv_results.mean(),4)}, ({round(cv_results.std(),4)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN: Home remedies myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unbalanced Classifier [(0.0, 324), (1.0, 28)]\n",
      "0.9318181818181818\n",
      "[[81  1]\n",
      " [ 5  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96        82\n",
      "         1.0       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.93        88\n",
      "   macro avg       0.72      0.58      0.61        88\n",
      "weighted avg       0.91      0.93      0.92        88\n",
      "\n",
      "\n",
      "Balanced Classifier [(0.0, 324), (1.0, 162)]\n",
      "0.8522727272727273\n",
      "[[71 11]\n",
      " [ 2  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.87      0.92        82\n",
      "         1.0       0.27      0.67      0.38         6\n",
      "\n",
      "    accuracy                           0.85        88\n",
      "   macro avg       0.62      0.77      0.65        88\n",
      "weighted avg       0.92      0.85      0.88        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Compare algorithms on validation test: KNN\n",
    "######################################################\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "knn_rem = KNeighborsClassifier()\n",
    "knn_rem.fit(X_train, Y_train)\n",
    "knn_predictions = knn_rem.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Unbalanced Classifier {Counter(Y_train).most_common()}')\n",
    "print(accuracy_score(Y_validate, knn_predictions))\n",
    "print(confusion_matrix(Y_validate, knn_predictions))\n",
    "print(classification_report(Y_validate, knn_predictions))\n",
    "\n",
    "######################################################\n",
    "# Balanced: Compare algorithms on validation test: KNN\n",
    "######################################################\n",
    "# Make predictions on validation dataset\n",
    "knn_rem = KNeighborsClassifier()\n",
    "knn_rem.fit(X_balanced, Y_balanced)\n",
    "knn_predictions = knn_rem.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Balanced Classifier {Counter(Y_balanced).most_common()}')\n",
    "print(accuracy_score(Y_validate, knn_predictions))\n",
    "print(confusion_matrix(Y_validate, knn_predictions))\n",
    "print(classification_report(Y_validate, knn_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest: Home remedies myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unbalanced Classifier [(0.0, 324), (1.0, 28)]\n",
      "0.9431818181818182\n",
      "[[82  0]\n",
      " [ 5  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97        82\n",
      "         1.0       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.94        88\n",
      "   macro avg       0.97      0.58      0.63        88\n",
      "weighted avg       0.95      0.94      0.92        88\n",
      "\n",
      "\n",
      "Balanced Classifier [(0.0, 324), (1.0, 162)]\n",
      "0.9431818181818182\n",
      "[[82  0]\n",
      " [ 5  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97        82\n",
      "         1.0       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.94        88\n",
      "   macro avg       0.97      0.58      0.63        88\n",
      "weighted avg       0.95      0.94      0.92        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Compare algorithms on validation test: Random Forest\n",
    "######################################################\n",
    "\n",
    "rf_rem = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "rf_rem.fit(X_train, Y_train) \n",
    "rf_predictions = rf_rem.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Unbalanced Classifier {Counter(Y_train).most_common()}')\n",
    "print(accuracy_score(Y_validate, rf_predictions))\n",
    "print(confusion_matrix(Y_validate, rf_predictions))\n",
    "print(classification_report(Y_validate, rf_predictions))\n",
    "\n",
    "######################################################\n",
    "# Balanced: Compare algorithms on validation test: Random Forest\n",
    "######################################################\n",
    "\n",
    "rf_rem = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "rf_rem.fit(X_balanced, Y_balanced) \n",
    "rf_predictions = rf_rem.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Balanced Classifier {Counter(Y_balanced).most_common()}')\n",
    "print(accuracy_score(Y_validate, rf_predictions))\n",
    "print(confusion_matrix(Y_validate, rf_predictions))\n",
    "print(classification_report(Y_validate, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Home remedies myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unbalanced Classifier [(0.0, 324), (1.0, 28)]\n",
      "0.8977272727272727\n",
      "[[78  4]\n",
      " [ 5  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.95        82\n",
      "         1.0       0.20      0.17      0.18         6\n",
      "\n",
      "    accuracy                           0.90        88\n",
      "   macro avg       0.57      0.56      0.56        88\n",
      "weighted avg       0.89      0.90      0.89        88\n",
      "\n",
      "\n",
      "Balanced Classifier [(0.0, 324), (1.0, 162)]\n",
      "0.8863636363636364\n",
      "[[77  5]\n",
      " [ 5  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.94      0.94        82\n",
      "         1.0       0.17      0.17      0.17         6\n",
      "\n",
      "    accuracy                           0.89        88\n",
      "   macro avg       0.55      0.55      0.55        88\n",
      "weighted avg       0.89      0.89      0.89        88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Compare algorithms on validation test: Decision Tree\n",
    "######################################################\n",
    "\n",
    "dt_rem = DecisionTreeClassifier()\n",
    "dt_rem.fit(X_train, Y_train)\n",
    "dt_predictions = dt_rem.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Unbalanced Classifier {Counter(Y_train).most_common()}')\n",
    "print(accuracy_score(Y_validate, dt_predictions))\n",
    "print(confusion_matrix(Y_validate, dt_predictions))\n",
    "print(classification_report(Y_validate, dt_predictions))\n",
    "\n",
    "######################################################\n",
    "# Balanced: Compare algorithms on validation test: Decision Tree\n",
    "######################################################\n",
    "\n",
    "dt_rem = DecisionTreeClassifier()\n",
    "dt_rem.fit(X_balanced, Y_balanced)\n",
    "dt_predictions = dt_rem.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Balanced Classifier {Counter(Y_balanced).most_common()}')\n",
    "print(accuracy_score(Y_validate, dt_predictions))\n",
    "print(confusion_matrix(Y_validate, dt_predictions))\n",
    "print(classification_report(Y_validate, dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Save best model\n",
    "######################################################\n",
    "\n",
    "# joblib.dump(rf_rem, rem_mod_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate algorithms: Weather myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train Distribution: [(1.0, 207), (0.0, 13)]\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Prepare training and validation data\n",
    "######################################################\n",
    "\n",
    "# Separate training and final validation data set. First remove class\n",
    "# label from data (X). Setup target class (Y)\n",
    "# Then make the validation set 10% of the entire\n",
    "# set of labeled data (X_validate, Y_validate)\n",
    "\n",
    "valueArray = wth_df_is_myth.values\n",
    "Y = valueArray[:,1]\n",
    "Y = Y.astype('float')\n",
    "test_size = 0.5\n",
    "seed = 15\n",
    "X_train, X_validate, Y_train, Y_validate = train_test_split(X_wth, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "print(f'Y_train Distribution: {Counter(Y_train).most_common()}')\n",
    "\n",
    "# Setup 10-fold cross validation to estimate the accuracy of different models\n",
    "# Split data into 10 parts\n",
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "# num_instances = len(X_train)\n",
    "seed = 7\n",
    "scoring = 'f1_weighted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Fold Cross Validation: Weather myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.9241, (0.0531)\n",
      "RF: 0.9979, (0.0062)\n",
      "DT: 0.9656, (0.0201)\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Use different algorithms to build models\n",
    "######################################################\n",
    "\n",
    "# Add each algorithm and its name to the model array\n",
    "models = []\n",
    "models.append(('KNN',KNeighborsClassifier()))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=1000, random_state=0)))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "\n",
    "# Evaluate each model, add results to a results array,\n",
    "# Print the accuracy results (remember these are averages and std)\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_balanced, Y_balanced, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f'{name}: {round(cv_results.mean(),4)}, ({round(cv_results.std(),4)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train: Counter({1.0: 207, 0.0: 13})\n",
      "Y_resample: Counter({1.0: 207, 0.0: 103})\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Undersample to minority size\n",
    "######################################################\n",
    "sampling_strategy = .5\n",
    "undersample = False\n",
    "\n",
    "X_balanced, Y_balanced = resample_data(X_train, Y_train, undersample=undersample, sampling_strategy=sampling_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN: Weather myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unbalanced Classifier [(1.0, 207), (0.0, 13)]\n",
      "0.9636363636363636\n",
      "[[  0   8]\n",
      " [  0 212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.96      1.00      0.98       212\n",
      "\n",
      "    accuracy                           0.96       220\n",
      "   macro avg       0.48      0.50      0.49       220\n",
      "weighted avg       0.93      0.96      0.95       220\n",
      "\n",
      "\n",
      "Balanced Classifier [(1.0, 207), (0.0, 103)]\n",
      "0.9181818181818182\n",
      "[[  1   7]\n",
      " [ 11 201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.08      0.12      0.10         8\n",
      "         1.0       0.97      0.95      0.96       212\n",
      "\n",
      "    accuracy                           0.92       220\n",
      "   macro avg       0.52      0.54      0.53       220\n",
      "weighted avg       0.93      0.92      0.93       220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ac1975/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Compare algorithms on validation test: KNN\n",
    "######################################################\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "# from sklearn.ensemble import BaggingClassifier # improves estimates but hard with so little data\n",
    "#knn_wth = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "\n",
    "knn_wth = KNeighborsClassifier()\n",
    "knn_wth.fit(X_train, Y_train)\n",
    "knn_predictions = knn_wth.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Unbalanced Classifier {Counter(Y_train).most_common()}')\n",
    "print(accuracy_score(Y_validate, knn_predictions))\n",
    "print(confusion_matrix(Y_validate, knn_predictions))\n",
    "print(classification_report(Y_validate, knn_predictions))\n",
    "\n",
    "######################################################\n",
    "# Balanced: Compare algorithms on validation test: KNN\n",
    "######################################################\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "# from sklearn.ensemble import BaggingClassifier # improves estimates but hard with so little data\n",
    "#knn_wth = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "\n",
    "knn_wth = KNeighborsClassifier()\n",
    "knn_wth.fit(X_balanced, Y_balanced)\n",
    "knn_predictions = knn_wth.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Balanced Classifier {Counter(Y_balanced).most_common()}')\n",
    "print(accuracy_score(Y_validate, knn_predictions))\n",
    "print(confusion_matrix(Y_validate, knn_predictions))\n",
    "print(classification_report(Y_validate, knn_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest: Weather myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unbalanced Classifier [(1.0, 207), (0.0, 13)]\n",
      "0.9636363636363636\n",
      "[[  0   8]\n",
      " [  0 212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.96      1.00      0.98       212\n",
      "\n",
      "    accuracy                           0.96       220\n",
      "   macro avg       0.48      0.50      0.49       220\n",
      "weighted avg       0.93      0.96      0.95       220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ac1975/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Classifier [(1.0, 207), (0.0, 103)]\n",
      "0.9636363636363636\n",
      "[[  0   8]\n",
      " [  0 212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.96      1.00      0.98       212\n",
      "\n",
      "    accuracy                           0.96       220\n",
      "   macro avg       0.48      0.50      0.49       220\n",
      "weighted avg       0.93      0.96      0.95       220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ac1975/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Compare algorithms on validation test: Random Forest\n",
    "######################################################\n",
    "\n",
    "#rf_wth = BaggingClassifier(RandomForestClassifier(n_estimators=1000, random_state=0), max_samples=0.5, max_features=0.5)\n",
    "\n",
    "rf_wth = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "rf_wth.fit(X_train, Y_train) \n",
    "rf_predictions = rf_wth.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Unbalanced Classifier {Counter(Y_train).most_common()}')\n",
    "print(accuracy_score(Y_validate, rf_predictions))\n",
    "print(confusion_matrix(Y_validate, rf_predictions))\n",
    "print(classification_report(Y_validate, rf_predictions))\n",
    "\n",
    "######################################################\n",
    "# Balanced: Compare algorithms on validation test: Random Forest\n",
    "######################################################\n",
    "\n",
    "#rf_wth = BaggingClassifier(RandomForestClassifier(n_estimators=1000, random_state=0), max_samples=0.5, max_features=0.5)\n",
    "\n",
    "rf_wth = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "rf_wth.fit(X_balanced, Y_balanced) \n",
    "rf_predictions = rf_wth.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Balanced Classifier {Counter(Y_balanced).most_common()}')\n",
    "print(accuracy_score(Y_validate, rf_predictions))\n",
    "print(confusion_matrix(Y_validate, rf_predictions))\n",
    "print(classification_report(Y_validate, rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Weather myths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unbalanced Classifier [(1.0, 207), (0.0, 13)]\n",
      "0.9363636363636364\n",
      "[[  0   8]\n",
      " [  6 206]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         8\n",
      "         1.0       0.96      0.97      0.97       212\n",
      "\n",
      "    accuracy                           0.94       220\n",
      "   macro avg       0.48      0.49      0.48       220\n",
      "weighted avg       0.93      0.94      0.93       220\n",
      "\n",
      "\n",
      "Balanced Classifier [(1.0, 207), (0.0, 103)]\n",
      "0.9090909090909091\n",
      "[[  4   4]\n",
      " [ 16 196]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.50      0.29         8\n",
      "         1.0       0.98      0.92      0.95       212\n",
      "\n",
      "    accuracy                           0.91       220\n",
      "   macro avg       0.59      0.71      0.62       220\n",
      "weighted avg       0.95      0.91      0.93       220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "# Compare algorithms on validation test: Decision Tree\n",
    "######################################################\n",
    "#dt_wth = BaggingClassifier(DecisionTreeClassifier(), max_samples=0.5, max_features=0.5)\n",
    "\n",
    "dt_wth = DecisionTreeClassifier()\n",
    "dt_wth.fit(X_train, Y_train)\n",
    "dt_predictions = dt_wth.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Unbalanced Classifier {Counter(Y_train).most_common()}')\n",
    "print(accuracy_score(Y_validate, dt_predictions))\n",
    "print(confusion_matrix(Y_validate, dt_predictions))\n",
    "print(classification_report(Y_validate, dt_predictions))\n",
    "\n",
    "######################################################\n",
    "# Balanced: Compare algorithms on validation test: Decision Tree\n",
    "######################################################\n",
    "#dt_wth = BaggingClassifier(DecisionTreeClassifier(), max_samples=0.5, max_features=0.5)\n",
    "\n",
    "dt_wth = DecisionTreeClassifier()\n",
    "dt_wth.fit(X_balanced, Y_balanced)\n",
    "dt_predictions = dt_wth.predict(X_validate)\n",
    "\n",
    "print()\n",
    "print(f'Balanced Classifier {Counter(Y_balanced).most_common()}')\n",
    "print(accuracy_score(Y_validate, dt_predictions))\n",
    "print(confusion_matrix(Y_validate, dt_predictions))\n",
    "print(classification_report(Y_validate, dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Save best model\n",
    "######################################################\n",
    "\n",
    "# joblib.dump(rf_wth, wth_mod_fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
